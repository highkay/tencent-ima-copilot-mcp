"""
IMA API å®¢æˆ·ç«¯å®ç°
"""
import asyncio
import base64
import json
import logging
import random
import re
import secrets
import string
import traceback
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, AsyncGenerator, Dict, List, Optional
from urllib.parse import unquote

import aiohttp

from models import (
    IMAConfig,
    IMARequest,
    IMAMessage,
    MessageType,
    KnowledgeBaseMessage,
    TextMessage,
    DeviceInfo,
    MCPToolResult,
    IMAStatus,
    TokenRefreshRequest,
    TokenRefreshResponse,
    InitSessionRequest,
    InitSessionResponse,
    EnvInfo,
    KnowledgeBaseInfoWithFolder,
)

logger = logging.getLogger(__name__)


class IMAAPIClient:
    """IMA API å®¢æˆ·ç«¯"""

    def __init__(self, config: IMAConfig):
        self.config = config
        self.base_url = "https://ima.qq.com"
        self.api_endpoint = "/cgi-bin/assistant/qa"
        self.refresh_endpoint = "/cgi-bin/auth_login/refresh"
        self.init_session_endpoint = "/cgi-bin/session_logic/init_session"
        self.session: Optional[aiohttp.ClientSession] = None
        self.current_session_id: Optional[str] = None
        self.session_initialized: bool = False
        self.raw_log_dir: Optional[Path] = None

        if getattr(self.config, "enable_raw_logging", False):
            raw_dir_value = getattr(self.config, "raw_log_dir", None)
            raw_dir = Path(raw_dir_value) if raw_dir_value else Path("logs") / "sse_raw"
            try:
                raw_dir.mkdir(parents=True, exist_ok=True)
                self.raw_log_dir = raw_dir
                logger.info(f"Raw SSE logs will be written to: {raw_dir}")
            except Exception as exc:
                logger.error(f"Failed to prepare raw SSE log directory: {exc}")

    def _should_persist_raw(self, stream_error: Optional[str]) -> bool:
        """åˆ¤æ–­å½“å‰æ˜¯å¦éœ€è¦ä¿å­˜åŸå§‹SSEå“åº”"""
        if not self.raw_log_dir or not getattr(self.config, "enable_raw_logging", False):
            return False

        if stream_error:
            return True  # always persist on errors

        return getattr(self.config, "raw_log_on_success", False)

    def _persist_raw_response(
        self,
        trace_id: str,
        attempt_index: int,
        question: Optional[str],
        full_response: str,
        message_count: int,
        parsed_message_count: int,
        failed_parse_count: int,
        elapsed_time: float,
        stream_error: Optional[str],
    ) -> Optional[Path]:
        """å°†åŸå§‹SSEå“åº”è½ç›˜ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜"""
        if not self._should_persist_raw(stream_error):
            return None

        assert self.raw_log_dir is not None  # for type checkers

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        suffix = f"attempt{attempt_index + 1}"
        filename = f"sse_{timestamp}_{trace_id}_{suffix}.log"
        target_path = self.raw_log_dir / filename

        max_bytes = getattr(self.config, "raw_log_max_bytes", 0) or 0
        encoded = full_response.encode("utf-8", errors="replace")
        response_bytes = len(encoded)
        truncated = False

        if max_bytes > 0 and response_bytes > max_bytes:
            encoded = encoded[:max_bytes]
            truncated = True

        preview_question = None
        if question:
            preview_question = question.strip()
            if len(preview_question) > 200:
                preview_question = preview_question[:200] + "..."

        metadata = {
            "timestamp": datetime.now().isoformat(),
            "trace_id": trace_id,
            "attempt": attempt_index + 1,
            "question": preview_question,
            "message_count": message_count,
            "parsed_message_count": parsed_message_count,
            "failed_parse_count": failed_parse_count,
            "elapsed_seconds": round(elapsed_time, 3),
            "response_bytes": response_bytes,
            "truncated": truncated,
            "stream_error": stream_error,
        }

        try:
            header = json.dumps(metadata, ensure_ascii=False, indent=2)
            body = encoded.decode("utf-8", errors="replace")

            with target_path.open("w", encoding="utf-8") as fp:
                fp.write(header)
                fp.write("\n\n")
                fp.write(body)

            logger.info(f"Raw SSE response saved to {target_path} (trace_id={trace_id})")
            return target_path
        except Exception as exc:
            logger.error(f"Failed to persist raw SSE response: {exc}")
            return None

    def _is_token_expired(self) -> bool:
        """æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ"""
        if not self.config.token_updated_at or not self.config.token_valid_time:
            return True
        
        expired_time = self.config.token_updated_at + timedelta(seconds=self.config.token_valid_time)
        return datetime.now() > expired_time

    def _parse_user_id_from_cookies(self) -> Optional[str]:
        """ä»IMA_X_IMA_COOKIEä¸­è§£æIMA-UID"""
        try:
            uid_pattern = r"IMA-UID=([^;]+)"
            match = re.search(uid_pattern, self.config.x_ima_cookie)
            if match:
                return match.group(1)

            user_id_pattern = r"user_id=([a-f0-9]{16})"
            if self.config.cookies:
                match = re.search(user_id_pattern, self.config.cookies)
                if match:
                    return match.group(1)
        except Exception as e:
            logger.warning(f"è§£æuser_idå¤±è´¥: {e}")
        return None

    def _parse_refresh_token_from_cookies(self) -> Optional[str]:
        """ä»IMA_X_IMA_COOKIEä¸­è§£æIMA-REFRESH-TOKEN"""
        try:
            refresh_token_pattern = r"IMA-REFRESH-TOKEN=([^;]+)"
            match = re.search(refresh_token_pattern, self.config.x_ima_cookie)
            if match:
                token = unquote(match.group(1))
                logger.info(f"æˆåŠŸä» x_ima_cookie è§£æ IMA-REFRESH-TOKEN (é•¿åº¦: {len(token)})")
                return token
            
            logger.warning("åœ¨ x_ima_cookie ä¸­æœªæ‰¾åˆ° IMA-REFRESH-TOKEN")
            
            token_pattern = r"IMA-TOKEN=([^;]+)"
            match = re.search(token_pattern, self.config.x_ima_cookie)
            if match:
                token = unquote(match.group(1))
                logger.warning(f"ä½¿ç”¨ IMA-TOKEN ä½œä¸º refresh_tokenï¼ˆé•¿åº¦: {len(token)}ï¼‰")
                return token

            if self.config.cookies:
                refresh_token_pattern = r"refresh_token=([^;]+)"
                match = re.search(refresh_token_pattern, self.config.cookies)
                if match:
                    token = unquote(match.group(1))
                    logger.info(f"æˆåŠŸä» cookies è§£æ refresh_token")
                    return token
            
            logger.warning("æœªèƒ½ä»ä»»ä½•æ¥æºè§£æåˆ° refresh_token")
        except Exception as e:
            logger.error(f"è§£æ refresh_token å¤±è´¥: {e}\n{traceback.format_exc()}")
        return None

    async def refresh_token(self) -> bool:
        """åˆ·æ–°è®¿é—®ä»¤ç‰Œ"""
        logger.info("ğŸ”„ å¼€å§‹åˆ·æ–° Token")
        
        if not self.config.user_id or not self.config.refresh_token:
            logger.info("ä» cookies ä¸­è§£æ user_id å’Œ refresh_token")
            self.config.user_id = self._parse_user_id_from_cookies()
            self.config.refresh_token = self._parse_refresh_token_from_cookies()

            if not self.config.user_id or not self.config.refresh_token:
                logger.warning("ç¼ºå°‘tokenåˆ·æ–°æ‰€éœ€çš„user_idæˆ–refresh_token")
                return False

        try:
            session = await self._get_session()

            # æ„å»ºåˆ·æ–°è¯·æ±‚
            refresh_request = TokenRefreshRequest(
                user_id=self.config.user_id,
                refresh_token=self.config.refresh_token
            )

            refresh_url = f"{self.base_url}{self.refresh_endpoint}"
            
            # æ„å»ºè¯·æ±‚å¤´ - æ·»åŠ  x-ima-bkn
            refresh_headers = {
                "accept": "*/*",
                "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
                "content-type": "application/json",
                "from_browser_ima": "1",
                "x-ima-cookie": self.config.x_ima_cookie,
                "x-ima-bkn": self.config.x_ima_bkn,
                "referer": "https://ima.qq.com/wikis"
            }
            
            request_body = refresh_request.model_dump()

            async with session.post(
                refresh_url,
                json=request_body,
                headers=refresh_headers
            ) as response:
                response_text = await response.text()
                if response.status == 200:
                    try:
                        response_data = await response.json()
                        refresh_response = TokenRefreshResponse(**response_data)

                        if refresh_response.code == 0 and refresh_response.token:
                            # æ›´æ–°tokenä¿¡æ¯
                            self.config.current_token = refresh_response.token
                            self.config.token_valid_time = int(refresh_response.token_valid_time or "7200")
                            self.config.token_updated_at = datetime.now()

                            logger.info(f"âœ… Tokenåˆ·æ–°æˆåŠŸ (æœ‰æ•ˆæœŸ: {self.config.token_valid_time}ç§’)")
                            return True
                        else:
                            logger.warning("=" * 60)
                            logger.warning(f"Tokenåˆ·æ–°å¤±è´¥")
                            logger.warning(f"  å“åº”ä»£ç : {refresh_response.code}")
                            logger.warning(f"  é”™è¯¯ä¿¡æ¯: {refresh_response.msg}")
                            # å°è¯•ä»åŸå§‹å“åº”æ•°æ®ä¸­è·å–æ›´å¤šé”™è¯¯ä¿¡æ¯
                            if 'type' in response_data:
                                logger.warning(f"  å“åº”ç±»å‹: {response_data['type']}")
                            if 'caused_by' in response_data:
                                logger.warning(f"  å¼•èµ·åŸå› : {response_data['caused_by']}")
                            logger.warning("=" * 60)
                            return False
                    except json.JSONDecodeError as je:
                        logger.error(f"æ— æ³•è§£æå“åº”ä¸º JSON: {je}")
                        logger.error(f"åŸå§‹å“åº”: {response_text[:200]}")
                        return False
                else:
                    logger.error("=" * 60)
                    logger.error(f"Tokenåˆ·æ–°è¯·æ±‚å¤±è´¥")
                    logger.error(f"  çŠ¶æ€ç : {response.status}")
                    logger.error(f"  å“åº”å†…å®¹: {response_text[:200]}")
                    logger.error("=" * 60)
                    return False

        except Exception as e:
            logger.error(f"Tokenåˆ·æ–°å¼‚å¸¸: {type(e).__name__}: {e}\n{traceback.format_exc()}")
            return False

    async def ensure_valid_token(self) -> bool:
        """ç¡®ä¿tokenæœ‰æ•ˆï¼Œå¦‚æœè¿‡æœŸåˆ™åˆ·æ–°"""
        if self._is_token_expired():
            if self.config.refresh_token and self.config.user_id:
                logger.info("Tokenå·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
                return await self.refresh_token()
            else:
                logger.info("å°è¯•ä»cookiesä¸­è§£ærefresh_tokenå¹¶ä¸»åŠ¨åˆ·æ–°...")
                self.config.user_id = self._parse_user_id_from_cookies()
                self.config.refresh_token = self._parse_refresh_token_from_cookies()
                
                if self.config.refresh_token and self.config.user_id:
                    logger.info("æˆåŠŸä»cookiesä¸­è§£æå‡­æ®ï¼Œå¼€å§‹åˆ·æ–°token...")
                    return await self.refresh_token()
                else:
                    logger.warning("æ— æ³•ä»cookiesä¸­è§£ærefresh_tokenï¼Œå°†ä½¿ç”¨åŸå§‹cookies")
                    return True

        return True

    
    def _parse_cookies(self, cookie_string: str) -> Dict[str, str]:
        """è§£æ Cookie å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        cookies = {}
        if not cookie_string:
            return cookies

        # å¤„ç†ä¸åŒæ ¼å¼çš„ Cookie å­—ç¬¦ä¸²
        cookie_parts = cookie_string.split(';')
        for part in cookie_parts:
            if '=' in part:
                name, value = part.strip().split('=', 1)
                cookies[name.strip()] = value.strip()
        return cookies

    def _build_headers(self, for_init_session: bool = False) -> Dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        x_ima_cookie = self.config.x_ima_cookie
        
        if self.config.current_token:
            x_ima_cookie = re.sub(
                r'IMA-TOKEN=[^;]+',
                f'IMA-TOKEN={self.config.current_token}',
                x_ima_cookie
            )
            
            if 'IMA-TOKEN=' not in x_ima_cookie:
                x_ima_cookie = x_ima_cookie + f'; IMA-TOKEN={self.config.current_token}'
        
        headers = {
            "x-ima-cookie": x_ima_cookie,
            "from_browser_ima": "1",
            "extension_version": "999.999.999",
            "x-ima-bkn": self.config.x_ima_bkn,
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "accept": "application/json" if for_init_session else "text/event-stream",
            "content-type": "application/json",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
            "sec-ch-ua": '"Microsoft Edge";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
        }

        if self.config.current_token:
            headers["authorization"] = f"Bearer {self.config.current_token}"
        
        return headers

    async def _get_session(self, for_init_session: bool = False) -> aiohttp.ClientSession:
        """è·å–æˆ–åˆ›å»º HTTP ä¼šè¯"""
        if self.session is None or self.session.closed:
            connector = aiohttp.TCPConnector(
                limit=100,
                limit_per_host=30,
                ttl_dns_cache=300,
                use_dns_cache=True,
                keepalive_timeout=60,
                enable_cleanup_closed=True,
            )

            timeout = aiohttp.ClientTimeout(
                total=min(self.config.timeout, 300),
                sock_read=180,
                connect=30,
                sock_connect=30,
            )

            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                cookies=self._parse_cookies(self.config.cookies or ""),
                headers=self._build_headers(for_init_session),
                trust_env=True,
                read_bufsize=5 * 2**20,
                auto_decompress=True,
            )

        return self.session

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯ä¼šè¯"""
        if self.session and not self.session.closed:
            await self.session.close()

    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ ID"""
        return ''.join(random.choices(string.ascii_lowercase + string.digits, k=24))

    def _generate_temp_uskey(self) -> str:
        """ç”Ÿæˆä¸´æ—¶ uskey"""
        return base64.b64encode(secrets.token_bytes(32)).decode('utf-8')

    def _build_request(self, question: str) -> IMARequest:
        """æ„å»º IMA API è¯·æ±‚"""
        session_id = self.current_session_id or self._generate_session_id()
        uskey = self._generate_temp_uskey()

        try:
            ima_guid = self.config.x_ima_cookie.split('IMA-GUID=')[1].split(';')[0]
        except (IndexError, AttributeError):
            ima_guid = "default_guid"

        device_info = DeviceInfo(
            uskey=uskey,
            uskey_bus_infos_input=f"{ima_guid}_{int(datetime.now().timestamp())}"
        )

        return IMARequest(
            session_id=session_id,
            robot_type=self.config.robot_type,
            question=question,
            question_type=2,
            client_id=self.config.client_id,
            command_info={
                "type": 14,
                "knowledge_qa_info": {
                    "tags": [],
                    "knowledge_ids": []
                }
            },
            model_info={
                "model_type": self.config.model_type,
                "enable_enhancement": False
            },
            history_info={},
            device_info=device_info
        )

    def _parse_sse_message(self, line: str) -> Optional[IMAMessage]:
        """è§£æ SSE æ¶ˆæ¯"""
        try:
            if line.startswith('data: '):
                data = line[6:]
            elif line.startswith(('event: ', 'id: ')):
                return None
            else:
                data = line

            if not data or data == '[DONE]' or not data.strip():
                return None

            json_data = json.loads(data)

            if 'msgs' in json_data and isinstance(json_data['msgs'], list):
                for msg in json_data['msgs']:
                    if isinstance(msg, dict) and 'content' in msg:
                        content = msg.get('content', '')
                        if content:
                            return TextMessage(
                                type=MessageType.TEXT,
                                content=content,
                                text=content,
                                raw=data
                            )
                return None

            if 'content' in json_data:
                content = json_data['content']
                if isinstance(content, str) and content:
                    return TextMessage(
                        type=MessageType.TEXT,
                        content=content,
                        text=content,
                        raw=data
                    )

            if 'Text' in json_data and isinstance(json_data['Text'], str):
                return TextMessage(
                    type=MessageType.TEXT,
                    content=json_data['Text'],
                    text=json_data['Text'],
                    raw=data
                )

            if 'type' in json_data and json_data['type'] == 'knowledgeBase':
                if 'content' not in json_data:
                    json_data['content'] = json_data.get('processing', 'çŸ¥è¯†åº“æœç´¢ä¸­...')
                return KnowledgeBaseMessage(**json_data)

            if 'question' in json_data and 'answer' in json_data:
                answer = json_data.get('answer', '')
                if answer:
                    return TextMessage(
                        type=MessageType.TEXT,
                        content=answer,
                        text=answer,
                        raw=data
                    )

            return IMAMessage(
                type=MessageType.SYSTEM,
                content=str(json_data),
                raw=data
            )

        except (json.JSONDecodeError, KeyError, ValueError):
            raise

    async def _process_sse_stream(
        self,
        response: aiohttp.ClientResponse,
        *,
        trace_id: str,
        attempt_index: int,
        question: Optional[str],
    ) -> AsyncGenerator[IMAMessage, None]:
        """å¤„ç† SSE æµ"""
        buffer = ""
        full_response = ""
        message_count = 0
        parsed_message_count = 0
        failed_parse_count = 0
        initial_timeout = 180
        chunk_timeout = 120
        last_data_time = asyncio.get_event_loop().time()
        start_time = asyncio.get_event_loop().time()
        has_received_data = False
        sample_chunks = []
        stream_error: Optional[str] = None

        try:
            logger.debug(f"ğŸ”„ [SSEæµ] å¼€å§‹è¯»å– (trace_id={trace_id})")
            async for chunk in response.content:
                current_time = asyncio.get_event_loop().time()

                timeout_threshold = chunk_timeout if has_received_data else initial_timeout
                elapsed_since_last_data = current_time - last_data_time
                
                if elapsed_since_last_data > timeout_threshold:
                    stream_error = f"Timeout after {elapsed_since_last_data:.1f}s with {message_count} chunks"
                    break

                if chunk:
                    has_received_data = True
                    last_data_time = current_time
                    message_count += 1

                    try:
                        chunk_str = chunk.decode('utf-8')
                    except UnicodeDecodeError:
                        # å°è¯•ä½¿ç”¨å…¶ä»–ç¼–ç æˆ–å¿½ç•¥æ— æ•ˆå­—èŠ‚
                        try:
                            chunk_str = chunk.decode('gbk')
                        except UnicodeDecodeError:
                            # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†æ¨¡å¼
                            chunk_str = chunk.decode('utf-8', errors='ignore')
                            logger.warning(f"Chunk {message_count} è§£ç å¤±è´¥")

                    buffer += chunk_str
                    full_response += chunk_str

                    while '\n' in buffer:
                        line, buffer = buffer.split('\n', 1)
                        line = line.strip()
                        if line:
                            try:
                                message = self._parse_sse_message(line)
                                if message:
                                    parsed_message_count += 1
                                    yield message
                            except (json.JSONDecodeError, KeyError, ValueError):
                                failed_parse_count += 1


        except asyncio.TimeoutError:
            if has_received_data and parsed_message_count > 0:
                stream_error = None
            else:
                stream_error = "SSE timeout"
                logger.error(f"âŒ [SSEæµ] è¶…æ—¶é”™è¯¯ï¼ˆæœªæ”¶åˆ°æ•°æ®ï¼‰, trace_id={trace_id}")
        except aiohttp.ClientPayloadError as exc:
            stream_error = f"SSE payload error: {exc}"
            logger.error(f"âŒ [SSEæµ] ClientPayloadError: {exc}, trace_id={trace_id}")
        except Exception as exc:
            stream_error = f"SSE exception: {exc}"
            logger.error(f"âŒ [SSEæµ] æœªçŸ¥å¼‚å¸¸: {type(exc).__name__}: {exc}, trace_id={trace_id}\n{traceback.format_exc()}")
        finally:
            # ç¡®ä¿å“åº”è¢«æ­£ç¡®å…³é—­
            if not response.closed:
                response.close()

            elapsed_time = asyncio.get_event_loop().time() - start_time
            self._persist_raw_response(
                trace_id=trace_id,
                attempt_index=attempt_index,
                question=question,
                full_response=full_response,
                message_count=message_count,
                parsed_message_count=parsed_message_count,
                failed_parse_count=failed_parse_count,
                elapsed_time=elapsed_time,
                stream_error=stream_error,
            )

        # å¤„ç†å‰©ä½™çš„ç¼“å†²åŒºå†…å®¹
        if buffer.strip():
            remaining_lines = buffer.strip().split('\n')
            for i, line in enumerate(remaining_lines):
                line = line.strip()
                if line:
                    try:
                        message = self._parse_sse_message(line)
                        if message:
                            parsed_message_count += 1
                            yield message
                    except (json.JSONDecodeError, KeyError, ValueError):
                        failed_parse_count += 1

        if message_count < 100 or not has_received_data:
            try:
                if full_response.strip():
                    response_data = json.loads(full_response.strip())
                    messages = self._extract_messages_from_response(response_data)
                    for message in messages:
                        yield message

            except json.JSONDecodeError:
                if full_response:
                    lines = full_response.split('\n')
                    for i, line in enumerate(lines):
                        line = line.strip()
                        if line and line != '[DONE]':
                            message = self._parse_sse_message(line)
                            if message:
                                parsed_message_count += 1
                                yield message
                            else:
                                failed_parse_count += 1

        elapsed_time = asyncio.get_event_loop().time() - start_time
        
        logger.info("=" * 80)
        logger.info(f"âœ… [SSEæµ] å¤„ç†å®Œæˆ (trace_id={trace_id})")
        logger.info(f"  æ”¶åˆ°æ•°æ®å—: {message_count} ä¸ª, æˆåŠŸè§£æ: {parsed_message_count} æ¡, å¤±è´¥: {failed_parse_count} æ¬¡")
        logger.info(f"  å“åº”å¤§å°: {len(full_response)} å­—èŠ‚, è€—æ—¶: {elapsed_time:.1f} ç§’")
        if stream_error:
            logger.info(f"  æµé”™è¯¯: {stream_error}")
        logger.info("=" * 80)

        if message_count > 100 and parsed_message_count < 5:
            logger.error(f"ä¸¥é‡: æ”¶åˆ° {message_count} ä¸ªchunkä½†åªè§£æå‡º {parsed_message_count} æ¡æ¶ˆæ¯ï¼Œ"
                        f"è§£æç‡ {(parsed_message_count/message_count*100):.1f}%")
            logger.debug(f"å‰10ä¸ªchunkæ ·æœ¬: {sample_chunks}")

    def _extract_messages_from_response(self, response_data: Dict[str, Any]) -> List[IMAMessage]:
        """ä»å®Œæ•´å“åº”ä¸­æå–æ¶ˆæ¯"""
        messages = []

        try:
            if 'msgs' in response_data and isinstance(response_data['msgs'], list):
                msgs_list = response_data['msgs']
                if msgs_list:
                    last_msg = msgs_list[-1]
                    if isinstance(last_msg, dict):
                        if last_msg.get('type') == 3:
                            qa_content = last_msg.get('content', {})
                            if isinstance(qa_content, dict):
                                answer = qa_content.get('answer', '')
                                if isinstance(answer, str) and answer:
                                    try:
                                        answer_data = json.loads(answer)
                                        if isinstance(answer_data, dict) and 'Text' in answer_data:
                                            text_content = answer_data['Text']
                                            messages.append(TextMessage(
                                                type=MessageType.TEXT,
                                                content=text_content,
                                                text=text_content,
                                                raw=str(last_msg)
                                            ))
                                        else:
                                            messages.append(TextMessage(
                                                type=MessageType.TEXT,
                                                content=answer,
                                                text=answer,
                                                raw=str(last_msg)
                                            ))
                                    except json.JSONDecodeError:
                                        messages.append(TextMessage(
                                            type=MessageType.TEXT,
                                            content=answer,
                                            text=answer,
                                            raw=str(last_msg)
                                        ))

                                context_refs = qa_content.get('context_refs', '')
                                if context_refs:
                                    try:
                                        context_data = json.loads(context_refs)
                                        if isinstance(context_data, dict):
                                            ref_text = "\n\nğŸ“š å‚è€ƒèµ„æ–™:\n"
                                            if 'medias' in context_data and isinstance(context_data['medias'], list):
                                                for i, media in enumerate(context_data['medias'][:5], 1):
                                                    title = media.get('title', f'èµ„æ–™{i}')
                                                    intro = media.get('introduction', '')
                                                    if intro:
                                                        intro = intro[:150] + "..." if len(intro) > 150 else intro
                                                        ref_text += f"{i}. {title}\n   {intro}\n"
                                                    else:
                                                        ref_text += f"{i}. {title}\n"

                                            if context_data.get('medias'):
                                                messages.append(TextMessage(
                                                    type=MessageType.TEXT,
                                                    content=ref_text,
                                                    text=ref_text,
                                                    raw=str(last_msg)
                                                ))
                                    except json.JSONDecodeError:
                                        messages.append(TextMessage(
                                            type=MessageType.TEXT,
                                            content=f"\n\nğŸ“š å‚è€ƒèµ„æ–™:\n{context_refs}",
                                            text=f"\n\nğŸ“š å‚è€ƒèµ„æ–™:\n{context_refs}",
                                            raw=str(last_msg)
                                        ))

            logger.info(f"ä»å“åº”ä¸­æå–äº† {len(messages)} æ¡æ¶ˆæ¯")
            return messages

        except Exception as e:
            logger.error(f"æå–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            messages.append(IMAMessage(
                type=MessageType.SYSTEM,
                content=str(response_data),
                raw=str(response_data)
            ))
            return messages

    async def init_session(self, knowledge_base_id: Optional[str] = None) -> str:
        """åˆå§‹åŒ–ä¼šè¯"""
        kb_id = knowledge_base_id or getattr(self.config, 'knowledge_base_id', '7305806844290061')

        logger.info(f"ğŸ”„ åˆå§‹åŒ–ä¼šè¯ (çŸ¥è¯†åº“: {kb_id})")
        if not await self.ensure_valid_token():
            logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
            raise ValueError("Authentication failed - unable to obtain valid token")
        
        session = await self._get_session(for_init_session=True)

        init_request = InitSessionRequest(
            envInfo=EnvInfo(
                robotType=5,
                interactType=0
            ),
            byKeyword=kb_id,
            relatedUrl=kb_id,
            sceneType=1,
            msgsLimit=0,
            forbidAutoAddToHistoryList=True,
            knowledgeBaseInfoWithFolder=KnowledgeBaseInfoWithFolder(
                knowledge_base_id=kb_id,
                folder_ids=[]
            )
        )
        
        url = f"{self.base_url}{self.init_session_endpoint}"
        request_json = init_request.model_dump()

        try:
            async with session.post(
                url,
                json=request_json,
                headers={"content-type": "application/json"}
            ) as response:
                if response.status != 200:
                    response_text = await response.text()
                    logger.error(f"åˆå§‹åŒ–ä¼šè¯å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status}")
                    logger.error(f"å“åº”å†…å®¹: {response_text}")
                    raise ValueError(f"init_session HTTPé”™è¯¯ {response.status}: {response_text[:500]}")
                
                response.raise_for_status()

                response_data = await response.json()
                init_response = InitSessionResponse(**response_data)

                if init_response.code == 0 and init_response.session_id:
                    self.current_session_id = init_response.session_id
                    self.session_initialized = True
                    logger.info(f"âœ… ä¼šè¯åˆå§‹åŒ–æˆåŠŸ (session_id: {self.current_session_id[:16]}...)")
                    return self.current_session_id
                else:
                    logger.error(f"âŒ ä¼šè¯åˆå§‹åŒ–å¤±è´¥ (code: {init_response.code}): {init_response.msg}")
                    raise ValueError(f"Session initialization failed (code: {init_response.code}): {init_response.msg}")

        except aiohttp.ClientError as e:
            logger.error(f"ä¼šè¯åˆå§‹åŒ–HTTPè¯·æ±‚å¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"ä¼šè¯åˆå§‹åŒ–å¼‚å¸¸: {e}")
            raise

    async def ask_question(self, question: str) -> AsyncGenerator[IMAMessage, None]:
        """å‘ IMA è¯¢é—®é—®é¢˜"""
        logger.debug(f"ğŸ” ask_question è¢«è°ƒç”¨ (session: {self.current_session_id[:16] if self.current_session_id else 'None'}...)")
        
        if not question.strip():
            raise ValueError("Question cannot be empty")

        # ç¡®ä¿tokenæœ‰æ•ˆ
        if not await self.ensure_valid_token():
            logger.error("âŒ [è¯Šæ–­] æ— æ³•è·å–æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
            raise ValueError("Authentication failed - unable to obtain valid token")

        # æ¯æ¬¡è°ƒç”¨éƒ½åˆå§‹åŒ–æ–°ä¼šè¯ï¼Œå®ç°ä¸Šä¸‹æ–‡éš”ç¦»
        logger.debug("ğŸ”„ åˆå§‹åŒ–æ–°ä¼šè¯ï¼ˆä¸Šä¸‹æ–‡éš”ç¦»ï¼‰")
        
        if self.session and not self.session.closed:
            await self.session.close()
            self.session = None
        
        # é‡ç½®ä¼šè¯çŠ¶æ€
        self.current_session_id = None
        self.session_initialized = False
        
        try:
            await self.init_session()
        except Exception as init_error:
            logger.error(f"âŒ [è¯Šæ–­] ä¼šè¯åˆå§‹åŒ–å¤±è´¥: {init_error}")
            logger.error("  è¿™å¯èƒ½æ˜¯å¯¼è‡´ 'No valid session ID provided' é”™è¯¯çš„åŸå› ")
            raise

        session = await self._get_session()
        request_data = self._build_request(question)

        url = f"{self.base_url}{self.api_endpoint}"
        request_json = request_data.model_dump()

        logger.debug(f"è¯·æ±‚URL: {url}")
        logger.debug(f"è¯·æ±‚å‚æ•°: {json.dumps(request_json, ensure_ascii=False, indent=2)}")

        # ç”Ÿæˆtrace_idç”¨äºè·Ÿè¸ª
        trace_id = str(uuid.uuid4())[:8]
        logger.debug(f"æœ¬æ¬¡è¯·æ±‚trace_id: {trace_id}")

        response = None
        try:
            logger.debug(f"å‘é€é—®é¢˜: {question[:50]}...")
            
            response = await session.post(
                url,
                json=request_json,
                headers={"content-type": "application/json"}
            )

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status != 200:
                response_text = await response.text()
                logger.error(f"âŒ [è¯Šæ–­] HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                logger.error(f"  å“åº”å†…å®¹: {response_text[:500]}...")
                
                # ç‰¹åˆ«æ£€æŸ¥ 400 é”™è¯¯å’Œ session ID ç›¸å…³çš„é—®é¢˜
                if response.status == 400:
                    logger.error("=" * 80)
                    logger.error("ğŸš¨ [è¯Šæ–­] æ”¶åˆ° HTTP 400 é”™è¯¯ - è¯¦ç»†è¯Šæ–­ä¿¡æ¯:")
                    logger.error("  å¯èƒ½çš„åŸå› :")
                    logger.error("    1. session_id æ— æ•ˆæˆ–å·²è¿‡æœŸ")
                    logger.error("    2. è®¤è¯ä¿¡æ¯ï¼ˆcookies/headersï¼‰æ— æ•ˆ")
                    logger.error("    3. è¯·æ±‚å‚æ•°æ ¼å¼é”™è¯¯")
                    logger.error(f"  å½“å‰ä½¿ç”¨çš„ session_id: {self.current_session_id}")
                    logger.error(f"  ä¼šè¯åˆå§‹åŒ–çŠ¶æ€: {self.session_initialized}")
                    logger.error(f"  HTTP session å¯¹è±¡: {self.session}")
                    logger.error(f"  HTTP session æ˜¯å¦å…³é—­: {self.session.closed if self.session else 'N/A'}")
                    logger.error(f"  Token æ˜¯å¦å­˜åœ¨: {bool(self.config.current_token)}")
                    logger.error(f"  Token æ›´æ–°æ—¶é—´: {self.config.token_updated_at}")
                    logger.error("=" * 80)
                
                raise ValueError(f"HTTPè¯·æ±‚å¤±è´¥: {response.status} - {response_text[:200]}")

            # æ£€æŸ¥å“åº”ç±»å‹
            content_type = response.headers.get('content-type', '')
            logger.debug(f"å“åº”ç±»å‹: {content_type}, çŠ¶æ€ç : {response.status}")

            if 'text/event-stream' not in content_type:
                # è¯»å–å“åº”å†…å®¹è¿›è¡Œè¯Šæ–­
                response_text = await response.text()
                logger.error(f"æ„å¤–çš„å“åº”ç±»å‹: {content_type}")
                
                if not response_text.strip():
                    logger.error("æ”¶åˆ°äº†ç©ºçš„é”™è¯¯å“åº”å†…å®¹ã€‚")
                    raise ValueError(f"Expected SSE response, got {content_type} with empty body. å¯èƒ½åŸå› : 1) è®¤è¯ä¿¡æ¯é”™è¯¯ 2) è¯·æ±‚å‚æ•°é—®é¢˜ 3) APIç«¯ç‚¹å˜æ›´")

                logger.error(f"å“åº”å†…å®¹ (å‰1000å­—ç¬¦): {response_text[:1000]}")

                # å°è¯•è§£æJSONé”™è¯¯å“åº”
                try:
                    error_data = json.loads(response_text)
                    error_msg = error_data.get('msg', 'æœªçŸ¥é”™è¯¯')
                    error_code = error_data.get('code', 'N/A')
                    logger.error(f"APIé”™è¯¯å“åº” (code: {error_code}): {error_msg}")
                    logger.debug(f"å®Œæ•´é”™è¯¯è¯¦æƒ…: {json.dumps(error_data, ensure_ascii=False, indent=2)}")
                    raise ValueError(f"APIè¿”å›é”™è¯¯ (code: {error_code}): {error_msg}")
                except json.JSONDecodeError:
                    logger.error("æ— æ³•å°†é”™è¯¯å“åº”è§£æä¸ºJSONã€‚")
                    logger.error(f"åŸå§‹å“åº”å†…å®¹: {response_text}")
                    raise ValueError(f"é¢„æœŸçš„SSEå“åº”ï¼Œä½†æ”¶åˆ° {content_type}ã€‚å“åº”æ— æ³•è§£æä¸ºJSON: {response_text[:200]}")

            # å¤„ç†æµå¼å“åº”
            message_count = 0
            async for message in self._process_sse_stream(
                response,
                trace_id=trace_id,
                attempt_index=0,
                question=question
            ):
                message_count += 1
                yield message

            # ç§»é™¤è¿™ä¸ªæ—¥å¿—ï¼Œå› ä¸ºåœ¨ _process_sse_stream ä¸­å·²ç»æœ‰æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

            # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•æ¶ˆæ¯ï¼Œè‡³å°‘è¿”å›ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯
            if message_count == 0:
                logger.warning("æœªæ”¶åˆ°æœ‰æ•ˆSSEæ¶ˆæ¯")
                yield IMAMessage(
                    type=MessageType.SYSTEM,
                    content="æœªæ”¶åˆ°æœ‰æ•ˆå“åº”ï¼Œä½†è¯·æ±‚å·²æˆåŠŸå‘é€",
                    raw="No valid SSE messages received"
                )

        except asyncio.TimeoutError as e:
            logger.error(f"è¯·æ±‚è¶…æ—¶: {e}")
            raise ValueError(f"è¯·æ±‚è¶…æ—¶: {str(e)}")
        except aiohttp.ClientError as e:
            logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {e}")
            raise ValueError(f"HTTPè¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"è¯¢é—®è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä½†åŒ…è£…ä¸ºæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            raise ValueError(f"è¯¢é—®å¤±è´¥: {str(e)}")
        finally:
            # ç¡®ä¿å“åº”è¢«æ­£ç¡®å…³é—­
            if response and not response.closed:
                response.close()

    def _is_login_expired_error(self, error_str: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯ç™»å½•è¿‡æœŸç›¸å…³é”™è¯¯"""
        login_expired_patterns = [
            "Session initialization failed",
            "ç™»å½•è¿‡æœŸ",
            "ç™»å½•å¤±è´¥",
            "authentication failed",
            "è®¤è¯å¤±è´¥",
            "code: 600001",
            "code: 600002",
            "code: 600003",
            "token expired",
            "ä¼šè¯å·²è¿‡æœŸ",
            "è¯·é‡æ–°ç™»å½•",
            "unauthorized",
            "401",
            "Expected SSE response",  # æœåŠ¡å™¨è¿”å›éSSEå“åº”é€šå¸¸æ„å‘³ç€ä¼šè¯/è®¤è¯å¤±è´¥
        ]

        error_lower = error_str.lower()
        return any(pattern.lower() in error_lower for pattern in login_expired_patterns)

    async def ask_question_complete(self, question: str) -> List[IMAMessage]:
        """è·å–å®Œæ•´çš„é—®é¢˜å›ç­” - æ”¯æŒè‡ªåŠ¨ token åˆ·æ–°é‡è¯•"""
        messages = []
        max_retries = 2  # æœ€å¤§é‡è¯•æ¬¡æ•°
        
        # ç”Ÿæˆä¸»trace_idç”¨äºæ•´ä¸ªè¯·æ±‚
        main_trace_id = str(uuid.uuid4())[:8]
        logger.info(f"ğŸš€ å¼€å§‹é—®ç­” (trace_id={main_trace_id}): {question[:50]}...")

        for attempt in range(max_retries + 1):  # æ€»å…±å°è¯• max_retries + 1 æ¬¡
            logger.debug(f"ğŸ“ å°è¯• {attempt + 1}/{max_retries + 1}")
            try:
                async for message in self.ask_question(question):
                    messages.append(message)
                    logger.debug(f"  æ”¶åˆ°æ¶ˆæ¯ #{len(messages)}: {type(message).__name__}")

                # å¦‚æœæˆåŠŸè·å–åˆ°æ¶ˆæ¯ï¼Œç›´æ¥è¿”å›
                if messages:
                    logger.info(f"âœ… é—®ç­”å®Œæˆ ({len(messages)}æ¡æ¶ˆæ¯)")
                    break
                else:
                    logger.warning(f"âš ï¸ [å®Œæ•´é—®ç­”] æœªè·å–åˆ°ä»»ä½•æ¶ˆæ¯ï¼Œå°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries + 1}")

            except Exception as e:
                error_str = str(e)
                logger.error("=" * 80)
                logger.error(f"âŒ [å®Œæ•´é—®ç­”] å°è¯• {attempt + 1}/{max_retries + 1} å¤±è´¥")
                logger.error(f"  å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                logger.error(f"  å¼‚å¸¸ä¿¡æ¯: {error_str[:200]}")
                logger.error("=" * 80)

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç™»å½•è¿‡æœŸé”™è¯¯
                if self._is_login_expired_error(error_str):
                    if attempt < max_retries:
                        logger.info(f"ğŸ”„ è®¤è¯é”™è¯¯ï¼Œåˆ·æ–°token...")

                        # å°è¯•åˆ·æ–° token
                        refresh_success = await self.refresh_token()
                        if refresh_success:
                            logger.info("âœ… Tokenåˆ·æ–°æˆåŠŸï¼Œé‡è¯•ä¸­...")
                            # é‡ç½®ä¼šè¯çŠ¶æ€ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
                            self.session_initialized = False
                            self.current_session_id = None
                            # å…³é—­ç°æœ‰ä¼šè¯ï¼Œé‡æ–°åˆ›å»º
                            if self.session and not self.session.closed:
                                await self.session.close()
                                self.session = None
                            # é‡ç½®æ¶ˆæ¯åˆ—è¡¨ï¼Œå‡†å¤‡é‡æ–°å°è¯•
                            messages = []
                            continue
                        else:
                            logger.error("âŒ [å®Œæ•´é—®ç­”] Tokenåˆ·æ–°å¤±è´¥ï¼Œåœæ­¢é‡è¯•")
                            break  # åˆ·æ–°å¤±è´¥ï¼Œç›´æ¥é€€å‡ºå¾ªç¯ï¼Œä¸å†é‡è¯•
                    else:
                        logger.error(f"âŒ [å®Œæ•´é—®ç­”] å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œåœæ­¢é‡è¯•")
                        break  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç›´æ¥é€€å‡ºå¾ªç¯
                else:
                    # å¦‚æœä¸æ˜¯ç™»å½•è¿‡æœŸé”™è¯¯ï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
                    if attempt < max_retries:
                        logger.info(f"ğŸ”„ [å®Œæ•´é—®ç­”] éè®¤è¯é”™è¯¯ï¼Œå»¶è¿Ÿ1ç§’åé‡è¯•...")
                        logger.info(f"  é”™è¯¯æ‘˜è¦: {error_str[:100]}")
                        # é‡ç½®æ¶ˆæ¯åˆ—è¡¨ï¼Œå‡†å¤‡é‡æ–°å°è¯•
                        messages = []
                        # çŸ­æš‚å»¶è¿Ÿåé‡è¯•
                        await asyncio.sleep(1)
                        continue
                    else:
                        logger.error(f"âŒ [å®Œæ•´é—®ç­”] å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œåœæ­¢é‡è¯•")
                        break  # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç›´æ¥é€€å‡ºå¾ªç¯

        # å¦‚æœå¾ªç¯ç»“æŸä½†æ²¡æœ‰æ¶ˆæ¯ï¼Œæ·»åŠ é”™è¯¯æ¶ˆæ¯
        if not messages:
            logger.error("=" * 80)
            logger.error(f"âŒ [å®Œæ•´é—®ç­”] æ‰€æœ‰å°è¯•å‡å¤±è´¥ï¼Œæœªè·å–åˆ°ä»»ä½•æ¶ˆæ¯")
            logger.error(f"  main_trace_id: {main_trace_id}")
            logger.error("=" * 80)
            error_message = IMAMessage(
                type=MessageType.SYSTEM,
                content=f"è·å–å›ç­”å¤±è´¥: æ‰€æœ‰ {max_retries + 1} æ¬¡å°è¯•å‡å¤±è´¥",
                raw="All retries exhausted"
            )
            messages.append(error_message)

        return messages

    def _extract_text_content(self, messages: List[IMAMessage]) -> str:
        """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–æ–‡æœ¬å†…å®¹ - ç°åœ¨åªå¤„ç†answerå’Œcontext_refsçš„æ‹¼æ¥"""
        if not messages:
            return "æ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”"

        content_parts = []

        for message in messages:
            if isinstance(message, TextMessage) and message.text:
                content_parts.append(message.text)
            elif hasattr(message, 'content') and message.content:
                content_parts.append(message.content)

        # æ‹¼æ¥æ‰€æœ‰å†…å®¹
        final_result = ''.join(content_parts).strip()

        # æ¸…ç†å’Œæ ¼å¼åŒ–ç»“æœ
        final_result = self._clean_response_content(final_result)

        logger.debug(f"æœ€ç»ˆå“åº”å†…å®¹é•¿åº¦: {len(final_result)}")
        return final_result

    def _clean_response_content(self, content: str) -> str:
        """æ¸…ç†å’Œæ ¼å¼åŒ–å“åº”å†…å®¹"""
        if not content:
            return content

        # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
        lines = content.split('\n')
        cleaned_lines = []
        prev_empty = False

        for line in lines:
            line = line.strip()
            if line:
                cleaned_lines.append(line)
                prev_empty = False
            elif not prev_empty:
                cleaned_lines.append('')
                prev_empty = True

        return '\n'.join(cleaned_lines)

    
    def _extract_knowledge_info(self, messages: List[IMAMessage]) -> List[Dict[str, Any]]:
        """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–çŸ¥è¯†åº“ä¿¡æ¯"""
        knowledge_items = []

        for message in messages:
            if isinstance(message, KnowledgeBaseMessage) and message.medias:
                for media in message.medias:
                    knowledge_items.append({
                        'id': media.id,
                        'title': media.title,
                        'subtitle': media.subtitle,
                        'introduction': media.introduction,
                        'timestamp': media.timestamp,
                        'knowledge_base': media.knowledge_base_info.name if media.knowledge_base_info else None
                    })

        return knowledge_items

    async def validate_config(self) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•é—®é¢˜
            test_messages = await self.ask_question_complete("æµ‹è¯•è¿æ¥")
            return len(test_messages) > 0
        except Exception as e:
            logger.error(f"Config validation failed: {e}")
            return False

    async def get_status(self) -> IMAStatus:
        """è·å–å®¢æˆ·ç«¯çŠ¶æ€"""
        status = IMAStatus()

        if not self.config:
            return status

        status.is_configured = True

        try:
            # éªŒè¯è®¤è¯çŠ¶æ€
            is_valid = await self.validate_config()
            status.is_authenticated = is_valid
            status.last_test_time = datetime.now()

            if not is_valid:
                status.error_message = "è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"

        except Exception as e:
            status.error_message = str(e)
            logger.error(f"Failed to get status: {e}")

        return status


class IMAToolExecutor:
    """IMA å·¥å…·æ‰§è¡Œå™¨"""

    def __init__(self, client: IMAAPIClient):
        self.client = client

    async def ask_question(self, question: str, include_knowledge: bool = True) -> MCPToolResult:
        """æ‰§è¡Œè¯¢é—®é—®é¢˜å·¥å…·"""
        try:
            messages = await self.client.ask_question_complete(question)

            if not messages:
                return MCPToolResult(
                    success=False,
                    content="",
                    error="æœªæ”¶åˆ°å“åº”"
                )

            # æå–ä¸»è¦å›ç­”å†…å®¹
            answer_text = self.client._extract_text_content(messages)

            # æ„å»ºå“åº”å†…å®¹
            content_parts = [f"**é—®é¢˜**: {question}\n\n**å›ç­”**:\n{answer_text}"]

            # æ·»åŠ çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_knowledge:
                knowledge_info = self.client._extract_knowledge_info(messages)
                if knowledge_info:
                    content_parts.append("\n\n**å‚è€ƒèµ„æ–™**:")
                    for i, item in enumerate(knowledge_info[:5], 1):  # æœ€å¤šæ˜¾ç¤º5ä¸ªå‚è€ƒèµ„æ–™
                        content_parts.append(f"{i}. {item['title']}")
                        if item.get('introduction'):
                            content_parts.append(f"   {item['introduction'][:100]}...")

            final_content = '\n'.join(content_parts)

            return MCPToolResult(
                success=True,
                content=final_content,
                metadata={
                    'message_count': len(messages),
                    'knowledge_sources': len(self.client._extract_knowledge_info(messages))
                }
            )

        except Exception as e:
            logger.error(f"Failed to execute ask_question: {e}")
            return MCPToolResult(
                success=False,
                content="",
                error=f"è¯¢é—®å¤±è´¥: {str(e)}"
            )

  
