"""
IMA API å®¢æˆ·ç«¯å®ç°
"""
import asyncio
import json
import logging
import re
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, AsyncGenerator, Dict, List, Optional, Union
from urllib.parse import unquote

import aiohttp

from models import (
    IMAConfig,
    IMARequest,
    IMAResponse,
    IMAMessage,
    MessageType,
    KnowledgeBaseMessage,
    TextMessage,
    DeviceInfo,
    MCPToolResult,
    IMAStatus,
    TokenRefreshRequest,
    TokenRefreshResponse,
    InitSessionRequest,
    InitSessionResponse,
    EnvInfo,
    KnowledgeBaseInfoWithFolder,
)

logger = logging.getLogger(__name__)


class IMAAPIClient:
    """IMA API å®¢æˆ·ç«¯"""

    def __init__(self, config: IMAConfig):
        self.config = config
        self.base_url = "https://ima.qq.com"
        self.api_endpoint = "/cgi-bin/assistant/qa"
        self.refresh_endpoint = "/cgi-bin/auth_login/refresh"
        self.init_session_endpoint = "/cgi-bin/session_logic/init_session"
        self.session: Optional[aiohttp.ClientSession] = None
        self.current_session_id: Optional[str] = None
        self.session_initialized: bool = False
        self.raw_log_dir: Optional[Path] = None

        if getattr(self.config, "enable_raw_logging", False):
            raw_dir_value = getattr(self.config, "raw_log_dir", None)
            raw_dir = Path(raw_dir_value) if raw_dir_value else Path("logs") / "sse_raw"
            try:
                raw_dir.mkdir(parents=True, exist_ok=True)
                self.raw_log_dir = raw_dir
                logger.info(f"Raw SSE logs will be written to: {raw_dir}")
            except Exception as exc:
                logger.error(f"Failed to prepare raw SSE log directory: {exc}")

    def _should_persist_raw(self, stream_error: Optional[str]) -> bool:
        """åˆ¤æ–­å½“å‰æ˜¯å¦éœ€è¦ä¿å­˜åŸå§‹SSEå“åº”"""
        if not self.raw_log_dir or not getattr(self.config, "enable_raw_logging", False):
            return False

        if stream_error:
            return True  # always persist on errors

        return getattr(self.config, "raw_log_on_success", False)

    def _persist_raw_response(
        self,
        trace_id: str,
        attempt_index: int,
        question: Optional[str],
        full_response: str,
        message_count: int,
        parsed_message_count: int,
        failed_parse_count: int,
        elapsed_time: float,
        stream_error: Optional[str],
    ) -> Optional[Path]:
        """å°†åŸå§‹SSEå“åº”è½ç›˜ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜"""
        if not self._should_persist_raw(stream_error):
            return None

        assert self.raw_log_dir is not None  # for type checkers

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        suffix = f"attempt{attempt_index + 1}"
        filename = f"sse_{timestamp}_{trace_id}_{suffix}.log"
        target_path = self.raw_log_dir / filename

        max_bytes = getattr(self.config, "raw_log_max_bytes", 0) or 0
        encoded = full_response.encode("utf-8", errors="replace")
        response_bytes = len(encoded)
        truncated = False

        if max_bytes > 0 and response_bytes > max_bytes:
            encoded = encoded[:max_bytes]
            truncated = True

        preview_question = None
        if question:
            preview_question = question.strip()
            if len(preview_question) > 200:
                preview_question = preview_question[:200] + "..."

        metadata = {
            "timestamp": datetime.now().isoformat(),
            "trace_id": trace_id,
            "attempt": attempt_index + 1,
            "question": preview_question,
            "message_count": message_count,
            "parsed_message_count": parsed_message_count,
            "failed_parse_count": failed_parse_count,
            "elapsed_seconds": round(elapsed_time, 3),
            "response_bytes": response_bytes,
            "truncated": truncated,
            "stream_error": stream_error,
        }

        try:
            header = json.dumps(metadata, ensure_ascii=False, indent=2)
            body = encoded.decode("utf-8", errors="replace")

            with target_path.open("w", encoding="utf-8") as fp:
                fp.write(header)
                fp.write("\n\n")
                fp.write(body)

            logger.info(f"Raw SSE response saved to {target_path} (trace_id={trace_id})")
            return target_path
        except Exception as exc:
            logger.error(f"Failed to persist raw SSE response: {exc}")
            return None

    def _is_token_expired(self) -> bool:
        """æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ"""
        if not self.config.token_updated_at or not self.config.token_valid_time:
            return True

        from datetime import timedelta
        expired_time = self.config.token_updated_at + timedelta(seconds=self.config.token_valid_time)
        return datetime.now() > expired_time

    def _parse_user_id_from_cookies(self) -> Optional[str]:
        """ä»IMA_X_IMA_COOKIEä¸­è§£æIMA-UID"""
        try:
            # ä»IMA_X_IMA_COOKIEä¸­æå–IMA-UID
            import re
            uid_pattern = r"IMA-UID=([^;]+)"
            match = re.search(uid_pattern, self.config.x_ima_cookie)
            if match:
                uid = match.group(1)
                logger.debug(f"æˆåŠŸè§£æIMA-UID: {uid}")
                return uid

            # å¦‚æœåœ¨IMA_X_IMA_COOKIEä¸­æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»cookiesä¸­æŸ¥æ‰¾
            user_id_pattern = r"user_id=([a-f0-9]{16})"
            if self.config.cookies:
                match = re.search(user_id_pattern, self.config.cookies)
                if match:
                    logger.info(f"ä»cookiesä¸­è§£æuser_id: {match.group(1)}")
                    return match.group(1)
        except Exception as e:
            logger.warning(f"è§£æuser_idå¤±è´¥: {e}")
        return None

    def _parse_refresh_token_from_cookies(self) -> Optional[str]:
        """ä»IMA_X_IMA_COOKIEä¸­è§£æIMA-REFRESH-TOKENï¼ˆç”¨äºåˆ·æ–°tokenï¼‰"""
        try:
            import re
            
            logger.debug(f"å¼€å§‹è§£æ refresh_token")
            logger.debug(f"  x_ima_cookie é•¿åº¦: {len(self.config.x_ima_cookie)}")
            logger.debug(f"  x_ima_cookie å‰100å­—ç¬¦: {self.config.x_ima_cookie[:100]}...")
            
            # ä¼˜å…ˆå°è¯•è§£æ IMA-REFRESH-TOKENï¼ˆè¿™æ˜¯æ­£ç¡®çš„åˆ·æ–°ä»¤ç‰Œï¼‰
            refresh_token_pattern = r"IMA-REFRESH-TOKEN=([^;]+)"
            match = re.search(refresh_token_pattern, self.config.x_ima_cookie)
            if match:
                token = match.group(1)
                decoded_token = unquote(token)
                if decoded_token != token:
                    logger.info(f"IMA-REFRESH-TOKEN å·²è¿›è¡Œ URL è§£ç ")
                    logger.info(f"  åŸå§‹é•¿åº¦: {len(token)}, è§£ç åé•¿åº¦: {len(decoded_token)}")
                    token = decoded_token
                
                logger.info(f"âœ“ æˆåŠŸä» x_ima_cookie è§£æ IMA-REFRESH-TOKEN")
                logger.info(f"  é•¿åº¦: {len(token)}")
                logger.info(f"  å‰20å­—ç¬¦: {token[:20]}...")
                logger.info(f"  å10å­—ç¬¦: ...{token[-10:]}")
                return token
            
            logger.warning("åœ¨ x_ima_cookie ä¸­æœªæ‰¾åˆ° IMA-REFRESH-TOKEN")
            
            # å¦‚æœæ‰¾ä¸åˆ° IMA-REFRESH-TOKENï¼Œå°è¯•å›é€€åˆ° IMA-TOKEN
            token_pattern = r"IMA-TOKEN=([^;]+)"
            match = re.search(token_pattern, self.config.x_ima_cookie)
            if match:
                token = match.group(1)
                decoded_token = unquote(token)
                if decoded_token != token:
                    token = decoded_token
                
                logger.warning(f"âš  ä½¿ç”¨ IMA-TOKEN ä½œä¸º refresh_tokenï¼ˆåº”è¯¥ä½¿ç”¨ IMA-REFRESH-TOKENï¼‰")
                logger.info(f"  é•¿åº¦: {len(token)}")
                logger.info(f"  å‰20å­—ç¬¦: {token[:20]}...")
                logger.info(f"  å10å­—ç¬¦: ...{token[-10:]}")
                return token

            logger.error("åœ¨ x_ima_cookie ä¸­æœªæ‰¾åˆ° IMA-TOKEN æˆ– IMA-REFRESH-TOKEN")

            # å¦‚æœåœ¨IMA_X_IMA_COOKIEä¸­æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»cookiesä¸­æŸ¥æ‰¾
            refresh_token_pattern = r"refresh_token=([^;]+)"
            if self.config.cookies:
                logger.debug(f"å°è¯•ä» cookies ä¸­è§£æ refresh_token")
                logger.debug(f"  cookies é•¿åº¦: {len(self.config.cookies)}")
                match = re.search(refresh_token_pattern, self.config.cookies)
                if match:
                    token = match.group(1)
                    decoded_token = unquote(token)
                    if decoded_token != token:
                        logger.info(f"refresh_token å·²è¿›è¡Œ URL è§£ç ")
                        token = decoded_token
                    
                    logger.info(f"æˆåŠŸä» cookies è§£æ refresh_token: {token[:20]}...")
                    return token
            
            logger.warning("æœªèƒ½ä»ä»»ä½•æ¥æºè§£æåˆ° refresh_token")
        except Exception as e:
            logger.error(f"è§£æ IMA-TOKEN å¤±è´¥: {e}")
            import traceback
            logger.error(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
        return None

    async def refresh_token(self) -> bool:
        """åˆ·æ–°è®¿é—®ä»¤ç‰Œ"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹åˆ·æ–° Token")
        
        if not self.config.user_id or not self.config.refresh_token:
            # å°è¯•ä»cookiesä¸­è§£æ
            logger.info("ä» cookies ä¸­è§£æ user_id å’Œ refresh_token")
            self.config.user_id = self._parse_user_id_from_cookies()
            self.config.refresh_token = self._parse_refresh_token_from_cookies()

            if not self.config.user_id or not self.config.refresh_token:
                logger.warning("ç¼ºå°‘tokenåˆ·æ–°æ‰€éœ€çš„user_idæˆ–refresh_token")
                logger.warning(f"  user_id å­˜åœ¨: {bool(self.config.user_id)}")
                logger.warning(f"  refresh_token å­˜åœ¨: {bool(self.config.refresh_token)}")
                return False

        # è®°å½•ç”¨äºåˆ·æ–°çš„å‡­æ®ä¿¡æ¯ï¼ˆéšè—æ•æ„Ÿéƒ¨åˆ†ï¼‰
        logger.info(f"ä½¿ç”¨çš„å‡­æ®:")
        logger.info(f"  user_id: {self.config.user_id}")
        logger.info(f"  refresh_token é•¿åº¦: {len(self.config.refresh_token)}")
        logger.info(f"  refresh_token å‰20å­—ç¬¦: {self.config.refresh_token[:20]}...")
        logger.info(f"  refresh_token å10å­—ç¬¦: ...{self.config.refresh_token[-10:]}")

        try:
            session = await self._get_session()

            # æ„å»ºåˆ·æ–°è¯·æ±‚
            refresh_request = TokenRefreshRequest(
                user_id=self.config.user_id,
                refresh_token=self.config.refresh_token
            )

            refresh_url = f"{self.base_url}{self.refresh_endpoint}"
            
            # æ„å»ºè¯·æ±‚å¤´ - æ·»åŠ  x-ima-bkn
            refresh_headers = {
                "accept": "*/*",
                "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
                "content-type": "application/json",
                "from_browser_ima": "1",
                "x-ima-cookie": self.config.x_ima_cookie,
                "x-ima-bkn": self.config.x_ima_bkn,
                "referer": "https://ima.qq.com/wikis"
            }

            logger.info(f"åˆ·æ–° Token URL: {refresh_url}")
            logger.info(f"è¯·æ±‚å¤´ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰:")
            for key, value in refresh_headers.items():
                if key.lower() in ['x-ima-cookie']:
                    logger.info(f"  {key}: [å·²éšè—ï¼Œé•¿åº¦={len(str(value))}]")
                else:
                    logger.info(f"  {key}: {value}")
            
            request_body = refresh_request.dict()
            logger.info(f"è¯·æ±‚ä½“:")
            logger.info(f"  user_id: {request_body['user_id']}")
            logger.info(f"  refresh_token é•¿åº¦: {len(request_body['refresh_token'])}")

            async with session.post(
                refresh_url,
                json=request_body,
                headers=refresh_headers
            ) as response:
                logger.info(f"æ”¶åˆ°åˆ·æ–°å“åº”ï¼ŒçŠ¶æ€ç : {response.status}")
                # è·å–å“åº”å†…å®¹
                response_text = await response.text()
                logger.info(f"å“åº”å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {response_text[:500]}")
                
                if response.status == 200:
                    try:
                        response_data = await response.json()
                        logger.info(f"è§£æåçš„å“åº”æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
                        refresh_response = TokenRefreshResponse(**response_data)

                        if refresh_response.code == 0 and refresh_response.token:
                            # æ›´æ–°tokenä¿¡æ¯
                            self.config.current_token = refresh_response.token
                            self.config.token_valid_time = int(refresh_response.token_valid_time or "7200")
                            self.config.token_updated_at = datetime.now()

                            logger.info("=" * 60)
                            logger.info("Tokenåˆ·æ–°æˆåŠŸ!")
                            logger.info(f"  æ–° token é•¿åº¦: {len(self.config.current_token)}")
                            logger.info(f"  æœ‰æ•ˆæœŸ: {self.config.token_valid_time} ç§’")
                            logger.info("=" * 60)
                            return True
                        else:
                            logger.warning("=" * 60)
                            logger.warning(f"Tokenåˆ·æ–°å¤±è´¥")
                            logger.warning(f"  å“åº”ä»£ç : {refresh_response.code}")
                            logger.warning(f"  é”™è¯¯ä¿¡æ¯: {refresh_response.msg}")
                            # å°è¯•ä»åŸå§‹å“åº”æ•°æ®ä¸­è·å–æ›´å¤šé”™è¯¯ä¿¡æ¯
                            if 'type' in response_data:
                                logger.warning(f"  å“åº”ç±»å‹: {response_data['type']}")
                            if 'caused_by' in response_data:
                                logger.warning(f"  å¼•èµ·åŸå› : {response_data['caused_by']}")
                            logger.warning("=" * 60)
                            return False
                    except json.JSONDecodeError as je:
                        logger.error(f"æ— æ³•è§£æå“åº”ä¸º JSON: {je}")
                        logger.error(f"åŸå§‹å“åº”: {response_text}")
                        return False
                else:
                    logger.error("=" * 60)
                    logger.error(f"Tokenåˆ·æ–°è¯·æ±‚å¤±è´¥")
                    logger.error(f"  çŠ¶æ€ç : {response.status}")
                    logger.error(f"  å“åº”å†…å®¹: {response_text}")
                    logger.error("=" * 60)
                    return False

        except Exception as e:
            logger.error("=" * 60)
            logger.error(f"Tokenåˆ·æ–°å¼‚å¸¸: {e}")
            logger.error(f"å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            logger.error(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            logger.error("=" * 60)
            return False

    async def ensure_valid_token(self) -> bool:
        """ç¡®ä¿tokenæœ‰æ•ˆï¼Œå¦‚æœè¿‡æœŸåˆ™åˆ·æ–°"""
        # å¦‚æœæ²¡æœ‰current_tokenï¼Œæˆ–è€…tokenè¿‡æœŸï¼Œå°è¯•åˆ·æ–°
        if self._is_token_expired():
            # å¦‚æœæœ‰refresh_tokenå’Œuser_idï¼Œå°è¯•åˆ·æ–°token
            if self.config.refresh_token and self.config.user_id:
                logger.info("Tokenå·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
                return await self.refresh_token()
            else:
                # å¦‚æœæ²¡æœ‰refresh_tokenï¼Œè¯´æ˜ä½¿ç”¨åŸºäºcookiesçš„è®¤è¯ï¼Œä¸éœ€è¦token
                logger.info("ä½¿ç”¨åŸºäºcookiesçš„è®¤è¯ï¼Œæ— éœ€tokenåˆ·æ–°")
                return True

        # Tokenä»ç„¶æœ‰æ•ˆ
        return True

    
    def _parse_cookies(self, cookie_string: str) -> Dict[str, str]:
        """è§£æ Cookie å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        cookies = {}
        if not cookie_string:
            return cookies

        # å¤„ç†ä¸åŒæ ¼å¼çš„ Cookie å­—ç¬¦ä¸²
        cookie_parts = cookie_string.split(';')
        for part in cookie_parts:
            if '=' in part:
                name, value = part.strip().split('=', 1)
                cookies[name.strip()] = value.strip()
        return cookies

    def _build_headers(self, for_init_session: bool = False) -> Dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        # å¦‚æœåˆ·æ–°äº† tokenï¼Œéœ€è¦æ›´æ–° x-ima-cookie ä¸­çš„ IMA-TOKEN
        x_ima_cookie = self.config.x_ima_cookie
        if self.config.current_token:
            # æ›¿æ¢ x-ima-cookie ä¸­çš„æ—§ IMA-TOKEN
            import re
            # å…ˆå°è¯•æ›¿æ¢ç°æœ‰çš„ IMA-TOKEN
            new_cookie = re.sub(
                r'IMA-TOKEN=[^;]+',
                f'IMA-TOKEN={self.config.current_token}',
                x_ima_cookie
            )
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° IMA-TOKENï¼Œåˆ™æ·»åŠ å®ƒ
            if new_cookie == x_ima_cookie and 'IMA-TOKEN=' not in x_ima_cookie:
                new_cookie = x_ima_cookie + f'; IMA-TOKEN={self.config.current_token}'
            x_ima_cookie = new_cookie
            logger.debug(f"å·²æ›´æ–° x-ima-cookie ä¸­çš„ IMA-TOKEN")
        
        headers = {
            "x-ima-cookie": x_ima_cookie,
            "from_browser_ima": "1",
            "extension_version": "999.999.999",
            "x-ima-bkn": self.config.x_ima_bkn,
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "accept": "application/json" if for_init_session else "text/event-stream",  # init_sessionæœŸæœ›JSONï¼ŒqaæœŸæœ›SSE
            "content-type": "application/json",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
            "sec-ch-ua": '"Microsoft Edge";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
        }

        # å¦‚æœæœ‰å½“å‰tokenï¼Œæ·»åŠ åˆ°è¯·æ±‚å¤´
        if self.config.current_token:
            headers["authorization"] = f"Bearer {self.config.current_token}"
            logger.debug(f"å·²æ·»åŠ  authorization è¯·æ±‚å¤´ (tokenå‰20å­—ç¬¦): {self.config.current_token[:20]}...")
        else:
            logger.debug("æœªæ·»åŠ  authorization è¯·æ±‚å¤´ (æ— current_token)")

        # è®°å½•å…³é”®è¯·æ±‚å¤´ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
        logger.debug(f"æ„å»ºè¯·æ±‚å¤´ - for_init_session={for_init_session}")
        logger.debug(f"  x-ima-cookie é•¿åº¦: {len(x_ima_cookie)}")
        logger.debug(f"  x-ima-bkn: {self.config.x_ima_bkn}")
        logger.debug(f"  cookies é•¿åº¦: {len(self.config.cookies or '')}")
        
        return headers

    async def _get_session(self, for_init_session: bool = False) -> aiohttp.ClientSession:
        """è·å–æˆ–åˆ›å»º HTTP ä¼šè¯"""
        if self.session is None or self.session.closed:
            connector = aiohttp.TCPConnector(
                limit=100,
                limit_per_host=30,
                ttl_dns_cache=300,
                use_dns_cache=True,
                # å¯ç”¨è¿æ¥æ± å’Œkeep-alive
                keepalive_timeout=60,
                enable_cleanup_closed=True,
            )

            # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥å¤„ç†å¤§å“åº”
            # å¯¹äºSSEæµï¼Œéœ€è¦æ›´é•¿çš„è¯»å–æ—¶é—´
            timeout = aiohttp.ClientTimeout(
                total=min(self.config.timeout, 120),  # æ€»è¶…æ—¶æœ€å¤š2åˆ†é’Ÿ
                sock_read=90,   # socket è¯»å–è¶…æ—¶å¢åŠ åˆ°90ç§’
                connect=30,     # è¿æ¥è¶…æ—¶
                sock_connect=30, # socketè¿æ¥è¶…æ—¶
            )

            # é…ç½®ä»£ç†ï¼ˆå¦‚æœè®¾ç½®ï¼‰
            proxy = None
            if self.config.proxy:
                proxy = self.config.proxy

            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                cookies=self._parse_cookies(self.config.cookies or ""),
                headers=self._build_headers(for_init_session),
                trust_env=True,
                # å¢åŠ è¯»å–ç¼“å†²åŒºå¤§å°
                read_bufsize=2**20,  # 1MB
                # å¯ç”¨è‡ªåŠ¨è§£å‹ç¼©
                auto_decompress=True,
            )

        return self.session

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯ä¼šè¯"""
        if self.session and not self.session.closed:
            await self.session.close()

    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ ID"""
        import random
        import string
        return ''.join(random.choices(string.ascii_lowercase + string.digits, k=24))

    def _generate_temp_uskey(self) -> str:
        """ç”Ÿæˆä¸´æ—¶ uskey"""
        import base64
        import secrets

        # ç”Ÿæˆ 32 å­—èŠ‚çš„éšæœºæ•°æ®
        random_bytes = secrets.token_bytes(32)
        # ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²
        return base64.b64encode(random_bytes).decode('utf-8')

    def _build_request(self, question: str) -> IMARequest:
        """æ„å»º IMA API è¯·æ±‚"""
        # ä½¿ç”¨ init_session è·å–çš„ session_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆä¸€ä¸ª
        session_id = self.current_session_id or self._generate_session_id()

        # å¦‚æœæ²¡æœ‰æä¾› uskeyï¼Œå°è¯•ç”Ÿæˆä¸€ä¸ªä¸´æ—¶çš„
        uskey = self.config.uskey
        if not uskey:
            uskey = self._generate_temp_uskey()

        # æå– IMA-GUID
        try:
            ima_guid = self.config.x_ima_cookie.split('IMA-GUID=')[1].split(';')[0]
        except (IndexError, AttributeError):
            ima_guid = "default_guid"

        device_info = DeviceInfo(
            uskey=uskey,
            uskey_bus_infos_input=f"{ima_guid}_{int(datetime.now().timestamp())}"
        )

        return IMARequest(
            session_id=session_id,
            robot_type=self.config.robot_type,
            question=question,
            question_type=2,
            client_id=self.config.client_id,
            command_info={
                "type": 14,
                "knowledge_qa_info": {
                    "tags": [],
                    "knowledge_ids": []
                }
            },
            model_info={
                "model_type": self.config.model_type,
                "enable_enhancement": False
            },
            history_info={},
            device_info=device_info
        )

    def _parse_sse_message(self, line: str) -> Optional[IMAMessage]:
        """è§£æ SSE æ¶ˆæ¯"""
        try:
            # ä¼˜åŒ–æ—¥å¿—ï¼šç§»é™¤é€è¡Œè§£æçš„DEBUGæ—¥å¿—ï¼Œå‡å°‘æ—¥å¿—é‡
            if line.startswith('data: '):
                data = line[6:]
            elif line.startswith(('event: ', 'id: ')):
                return None  # è·³è¿‡SSEæ§åˆ¶æ¶ˆæ¯
            else:
                data = line

            if not data or data == '[DONE]' or not data.strip():
                return None  # è·³è¿‡ç©ºè¡Œæˆ–ç»“æŸæ ‡è®°

            # è§£æ JSON æ•°æ®
            json_data = json.loads(data)

            # å¤„ç†ä¸åŒçš„æ¶ˆæ¯æ ¼å¼
            # æ ¼å¼1: åŒ…å«æ¶ˆæ¯åˆ—è¡¨çš„å“åº”
            if 'msgs' in json_data and isinstance(json_data['msgs'], list):
                # è¿™æ˜¯æœ€ç»ˆå“åº”ï¼ŒåŒ…å«å¤šä¸ªæ¶ˆæ¯
                for i, msg in enumerate(json_data['msgs']):
                    if isinstance(msg, dict) and 'content' in msg:
                        # æå–å†…å®¹
                        content = msg.get('content', '')
                        if content:
                            return TextMessage(
                                type=MessageType.TEXT,
                                content=content,
                                text=content,
                                raw=data
                            )
                return None

            # æ ¼å¼2: ç›´æ¥åŒ…å«å†…å®¹å­—æ®µ
            if 'content' in json_data:
                content = json_data['content']
                if isinstance(content, str) and content:
                    return TextMessage(
                        type=MessageType.TEXT,
                        content=content,
                        text=content,
                        raw=data
                    )

            # æ ¼å¼3: åŒ…å« Text å­—æ®µ
            if 'Text' in json_data and isinstance(json_data['Text'], str):
                return TextMessage(
                    type=MessageType.TEXT,
                    content=json_data['Text'],
                    text=json_data['Text'],
                    raw=data
                )

            # æ ¼å¼4: çŸ¥è¯†åº“æ¶ˆæ¯
            if 'type' in json_data and json_data['type'] == 'knowledgeBase':
                # ç¡®ä¿contentå­—æ®µå­˜åœ¨
                if 'content' not in json_data:
                    json_data['content'] = json_data.get('processing', 'çŸ¥è¯†åº“æœç´¢ä¸­...')
                return KnowledgeBaseMessage(**json_data)

            # æ ¼å¼5: å…¶ä»–æ ¼å¼çš„æ¶ˆæ¯ï¼Œå°è¯•æå–æœ‰ç”¨ä¿¡æ¯
            if 'question' in json_data and 'answer' in json_data:
                # é—®ç­”æ ¼å¼
                answer = json_data.get('answer', '')
                if answer:
                    return TextMessage(
                        type=MessageType.TEXT,
                        content=answer,
                        text=answer,
                        raw=data
                    )

            # å¦‚æœéƒ½æ— æ³•åŒ¹é…ï¼Œå°†æ•´ä¸ªJSONä½œä¸ºå†…å®¹
            return IMAMessage(
                type=MessageType.SYSTEM,
                content=str(json_data),
                raw=data
            )

        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.debug(f"Failed to parse SSE message: {e}, line: {line[:100]}...")
            raise  # Re-raise the exception to be caught upstream

    async def _process_sse_stream(
        self,
        response: aiohttp.ClientResponse,
        *,
        trace_id: str,
        attempt_index: int,
        question: Optional[str],
    ) -> AsyncGenerator[IMAMessage, None]:
        """å¤„ç† SSE æµ - å®Œæ•´å¤„ç†æ‰€æœ‰æ¶ˆæ¯"""
        buffer = ""
        full_response = ""
        message_count = 0
        parsed_message_count = 0  # æˆåŠŸè§£æçš„æ¶ˆæ¯æ•°
        failed_parse_count = 0  # è§£æå¤±è´¥çš„chunkæ•°
        no_data_timeout = 120  # å¢åŠ åˆ°120ç§’æ— æ•°æ®è¶…æ—¶,ä¸total timeoutä¸€è‡´
        chunk_timeout = 60  # å¢åŠ åˆ°60ç§’ä»¥å¤„ç†æ…¢é€Ÿå“åº”
        last_data_time = asyncio.get_event_loop().time()
        start_time = asyncio.get_event_loop().time()
        has_received_data = False  # æ ‡è®°æ˜¯å¦æ”¶åˆ°è¿‡æ•°æ®
        first_chunk_logged = False  # æ˜¯å¦å·²è®°å½•ç¬¬ä¸€ä¸ªchunk
        sample_chunks = []  # ä¿å­˜å‰10ä¸ªchunkæ ·æœ¬ç”¨äºåˆ†æ

        stream_error: Optional[str] = None
        raw_log_path: Optional[Path] = None

        # è®°å½•å¼€å§‹å¤„ç†SSEæµ
        logger.debug(f"å¼€å§‹å¤„ç†SSEæµ (trace_id={trace_id}, attempt={attempt_index + 1})")

        try:
            async for chunk in response.content:
                current_time = asyncio.get_event_loop().time()

                # åŠ¨æ€è¶…æ—¶æ£€æŸ¥:å¦‚æœå·²ç»æ”¶åˆ°æ•°æ®,ä½¿ç”¨è¾ƒçŸ­çš„chunkè¶…æ—¶;å¦åˆ™ä½¿ç”¨å®Œæ•´è¶…æ—¶
                timeout_threshold = chunk_timeout if has_received_data else no_data_timeout
                if current_time - last_data_time > timeout_threshold:
                    logger.warning(f"SSE æµè¯»å–è¶…æ—¶ï¼Œæ— æ•°æ®æ—¶é—´è¶…è¿‡{timeout_threshold}ç§’ (å·²å¤„ç†{message_count}æ¡æ¶ˆæ¯)")
                    logger.debug(f"è¶…æ—¶æ—¶çš„çŠ¶æ€ - bufferé•¿åº¦: {len(buffer)}, å·²å¤„ç†æ•°æ®: {len(full_response)}å­—èŠ‚")
                    logger.debug(f"è¶…æ—¶æ—¶çš„ç»Ÿè®¡ - æˆåŠŸè§£æ: {parsed_message_count}, å¤±è´¥è§£æ: {failed_parse_count}")
                    # ä¸æ˜¯ç«‹å³ä¸­æ–­,è€Œæ˜¯å°è¯•è§£æå·²æ¥æ”¶çš„æ•°æ®
                    break

                if chunk:
                    has_received_data = True
                    last_data_time = current_time
                    message_count += 1

                    # ä¿å­˜å‰10ä¸ªchunkæ ·æœ¬
                    if len(sample_chunks) < 10:
                        sample_chunks.append({
                            'chunk_num': message_count,
                            'size': len(chunk),
                            'content_preview': chunk.decode('utf-8', errors='ignore')[:100]
                        })

                    try:
                        chunk_str = chunk.decode('utf-8')
                    except UnicodeDecodeError:
                        # å°è¯•ä½¿ç”¨å…¶ä»–ç¼–ç æˆ–å¿½ç•¥æ— æ•ˆå­—èŠ‚
                        try:
                            chunk_str = chunk.decode('gbk')
                        except UnicodeDecodeError:
                            # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†æ¨¡å¼
                            chunk_str = chunk.decode('utf-8', errors='ignore')
                            logger.warning(f"Chunk {message_count} è§£ç å¤±è´¥ï¼Œä½¿ç”¨ignoreæ¨¡å¼")

                    first_chunk_logged = True

                    buffer += chunk_str
                    full_response += chunk_str

                    # å¤„ç†å®Œæ•´çš„è¡Œ
                    lines_in_chunk = 0
                    while '\n' in buffer:
                        line, buffer = buffer.split('\n', 1)
                        line = line.strip()
                        lines_in_chunk += 1

                        if line:
                            try:
                                message = self._parse_sse_message(line)
                                if message:
                                    parsed_message_count += 1
                                    yield message
                            except (json.JSONDecodeError, KeyError, ValueError):
                                failed_parse_count += 1


        except asyncio.TimeoutError as exc:
            stream_error = f"SSE timeout: {exc}"
            logger.error("SSE æµè¯»å–è¶…æ—¶")
            raise
        except aiohttp.ClientPayloadError as exc:
            stream_error = f"SSE payload error: {exc}"
            logger.error(f"SSE æµæ•°æ®é”™è¯¯: {exc}")
            raise
        except Exception as exc:
            stream_error = f"SSE exception: {exc}"
            logger.error(f"SSE æµå¤„ç†å¼‚å¸¸: {exc}")
            raise
        finally:
            # ç¡®ä¿å“åº”è¢«æ­£ç¡®å…³é—­
            if not response.closed:
                response.close()

            elapsed_time = asyncio.get_event_loop().time() - start_time
            raw_log_path = self._persist_raw_response(
                trace_id=trace_id,
                attempt_index=attempt_index,
                question=question,
                full_response=full_response,
                message_count=message_count,
                parsed_message_count=parsed_message_count,
                failed_parse_count=failed_parse_count,
                elapsed_time=elapsed_time,
                stream_error=stream_error,
            )

        # å¤„ç†å‰©ä½™çš„ç¼“å†²åŒºå†…å®¹
        if buffer.strip():
            remaining_lines = buffer.strip().split('\n')
            for i, line in enumerate(remaining_lines):
                line = line.strip()
                if line:
                    try:
                        message = self._parse_sse_message(line)
                        if message:
                            parsed_message_count += 1
                            yield message
                    except (json.JSONDecodeError, KeyError, ValueError):
                        failed_parse_count += 1

        # å¦‚æœæ²¡æœ‰ä» SSE æµä¸­è§£æåˆ°è¶³å¤Ÿæ¶ˆæ¯ï¼Œå°è¯•å°†æ•´ä¸ªå“åº”ä½œä¸º JSON å¤„ç†
        # è¿™æ˜¯ä¸ºäº†å¤„ç† IMA å¯èƒ½è¿”å›çš„å®Œæ•´ JSON å“åº”
        if message_count < 100 or not has_received_data:  # æ¶ˆæ¯è¾ƒå°‘æˆ–æ²¡æ”¶åˆ°æ•°æ®æ—¶å°è¯•å®Œæ•´è§£æ
            # å°è¯•è§£ææ•´ä¸ªå“åº”ä¸º JSON
            try:
                if full_response.strip():
                    response_data = json.loads(full_response.strip())
                    # å°è¯•ä»å“åº”ä¸­æå–æœ‰ç”¨ä¿¡æ¯
                    messages = self._extract_messages_from_response(response_data)
                    for message in messages:
                        yield message

            except json.JSONDecodeError as e:
                # æœ€åå°è¯•ï¼šé€è¡Œè§£æå“åº”
                if full_response:
                    lines = full_response.split('\n')
                    for i, line in enumerate(lines):
                        line = line.strip()
                        if line and line != '[DONE]':
                            message = self._parse_sse_message(line)
                            if message:
                                parsed_message_count += 1
                                yield message
                            else:
                                failed_parse_count += 1

        # è®°å½•æœ€ç»ˆå¤„ç†ç»Ÿè®¡
        elapsed_time = asyncio.get_event_loop().time() - start_time
        parse_rate = (parsed_message_count / message_count * 100) if message_count > 0 else 0
        extra_info = f"ï¼ŒåŸå§‹æ—¥å¿—: {raw_log_path}" if raw_log_path else ""
        logger.info(f"SSE æµå¤„ç†ç»“æŸ: æ”¶åˆ° {message_count} ä¸ªæ•°æ®å—, "
                   f"æˆåŠŸè§£æ {parsed_message_count} æ¡æ¶ˆæ¯, "
                   f"å¤±è´¥ {failed_parse_count} æ¬¡, "
                   f"å“åº”å¤§å° {len(full_response)} å­—èŠ‚, è€—æ—¶ {elapsed_time:.1f} ç§’{extra_info}")

        # è¯Šæ–­æ€§æ—¥å¿—
        # è¯Šæ–­æ€§æ—¥å¿— - ä»…åœ¨å‡ºç°ä¸¥é‡è§£æé—®é¢˜æ—¶è®°å½•
        if message_count > 100 and parsed_message_count < 5:
            logger.error(f"ä¸¥é‡: æ”¶åˆ° {message_count} ä¸ªchunkä½†åªè§£æå‡º {parsed_message_count} æ¡æ¶ˆæ¯ï¼Œ"
                        f"è§£æç‡ {(parsed_message_count/message_count*100):.1f}%")
            logger.debug(f"å‰10ä¸ªchunkæ ·æœ¬: {sample_chunks}")

    def _extract_messages_from_response(self, response_data: Dict[str, Any]) -> List[IMAMessage]:
        """ä»å®Œæ•´å“åº”ä¸­æå–æ¶ˆæ¯ - åªå…³æ³¨qaè¿”å›çš„msgsä¸­æœ€åä¸€ä¸ªå¯¹è±¡"""
        messages = []

        try:
            # æŸ¥æ‰¾qaå“åº”ä¸­çš„msgsåˆ—è¡¨
            if 'msgs' in response_data and isinstance(response_data['msgs'], list):
                msgs_list = response_data['msgs']
                if msgs_list:
                    # è·å–æœ€åä¸€ä¸ªæ¶ˆæ¯å¯¹è±¡
                    last_msg = msgs_list[-1]
                    if isinstance(last_msg, dict):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯qaæ¶ˆæ¯ç±»å‹ (type: 3)
                        if last_msg.get('type') == 3:
                            qa_content = last_msg.get('content', {})
                            if isinstance(qa_content, dict):
                                # æå–answerå†…å®¹
                                answer = qa_content.get('answer', '')
                                if isinstance(answer, str) and answer:
                                    # è§£æanswerä¸­çš„JSONï¼ˆé€šå¸¸æ˜¯è½¬ä¹‰çš„ï¼‰
                                    try:
                                        answer_data = json.loads(answer)
                                        if isinstance(answer_data, dict) and 'Text' in answer_data:
                                            text_content = answer_data['Text']
                                            messages.append(TextMessage(
                                                type=MessageType.TEXT,
                                                content=text_content,
                                                text=text_content,
                                                raw=str(last_msg)
                                            ))
                                        else:
                                            # å¦‚æœä¸æ˜¯é¢„æœŸçš„æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨answerå†…å®¹
                                            messages.append(TextMessage(
                                                type=MessageType.TEXT,
                                                content=answer,
                                                text=answer,
                                                raw=str(last_msg)
                                            ))
                                    except json.JSONDecodeError:
                                        # å¦‚æœæ— æ³•è§£æJSONï¼Œç›´æ¥ä½¿ç”¨answerå†…å®¹
                                        messages.append(TextMessage(
                                            type=MessageType.TEXT,
                                            content=answer,
                                            text=answer,
                                            raw=str(last_msg)
                                        ))

                                # æå–context_refså†…å®¹
                                context_refs = qa_content.get('context_refs', '')
                                if context_refs:
                                    # è§£æcontext_refsï¼ˆé€šå¸¸æ˜¯JSONæ ¼å¼çš„å‚è€ƒèµ„æ–™ï¼‰
                                    try:
                                        context_data = json.loads(context_refs)
                                        if isinstance(context_data, dict):
                                            # æ„å»ºå‚è€ƒèµ„æ–™æ–‡æœ¬
                                            ref_text = "\n\nğŸ“š å‚è€ƒèµ„æ–™:\n"
                                            if 'medias' in context_data and isinstance(context_data['medias'], list):
                                                for i, media in enumerate(context_data['medias'][:5], 1):  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                                                    title = media.get('title', f'èµ„æ–™{i}')
                                                    intro = media.get('introduction', '')
                                                    if intro:
                                                        intro = intro[:150] + "..." if len(intro) > 150 else intro
                                                        ref_text += f"{i}. {title}\n   {intro}\n"
                                                    else:
                                                        ref_text += f"{i}. {title}\n"

                                            # å°†å‚è€ƒèµ„æ–™ä½œä¸ºæ–‡æœ¬æ¶ˆæ¯æ·»åŠ 
                                            if context_data.get('medias'):
                                                messages.append(TextMessage(
                                                    type=MessageType.TEXT,
                                                    content=ref_text,
                                                    text=ref_text,
                                                    raw=str(last_msg)
                                                ))
                                    except json.JSONDecodeError:
                                        # å¦‚æœæ— æ³•è§£æJSONï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬å¤„ç†
                                        messages.append(TextMessage(
                                            type=MessageType.TEXT,
                                            content=f"\n\nğŸ“š å‚è€ƒèµ„æ–™:\n{context_refs}",
                                            text=f"\n\nğŸ“š å‚è€ƒèµ„æ–™:\n{context_refs}",
                                            raw=str(last_msg)
                                        ))

            logger.info(f"ä»å“åº”ä¸­æå–äº† {len(messages)} æ¡æ¶ˆæ¯ï¼ˆä»…å¤„ç†qa msgsä¸­æœ€åä¸€ä¸ªå¯¹è±¡ï¼‰")
            return messages

        except Exception as e:
            logger.error(f"æå–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›åŸå§‹å†…å®¹ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯
            messages.append(IMAMessage(
                type=MessageType.SYSTEM,
                content=str(response_data),
                raw=str(response_data)
            ))
            return messages

    async def init_session(self, knowledge_base_id: Optional[str] = None) -> str:
        """åˆå§‹åŒ–ä¼šè¯ï¼Œè·å–æœ‰æ•ˆçš„ session_id"""
        # ä½¿ç”¨é…ç½®ä¸­çš„çŸ¥è¯†åº“IDï¼Œå¦‚æœæ²¡æœ‰æä¾›å‚æ•°
        kb_id = knowledge_base_id or getattr(self.config, 'knowledge_base_id', '7305806844290061')

        logger.info("=" * 60)
        logger.info("å¼€å§‹åˆå§‹åŒ–ä¼šè¯ (init_session)")
        logger.info(f"çŸ¥è¯†åº“ID: {kb_id}")
        
        # ç¡®ä¿tokenæœ‰æ•ˆ
        if not await self.ensure_valid_token():
            logger.error("æ— æ³•è·å–æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
            raise ValueError("Authentication failed - unable to obtain valid token")

        session = await self._get_session(for_init_session=True)
        
        # è®°å½•å½“å‰ä¼šè¯çš„cookieså’Œheaders
        logger.info(f"ä¼šè¯cookiesæ•°é‡: {len(session.cookie_jar)}")
        logger.info(f"ä¼šè¯headers: {dict(session.headers)}")

        # æ„å»ºåˆå§‹åŒ–è¯·æ±‚
        init_request = InitSessionRequest(
            envInfo=EnvInfo(
                robotType=5,
                interactType=0
            ),
            byKeyword=kb_id,
            relatedUrl=kb_id,
            sceneType=1,
            msgsLimit=10,
            forbidAutoAddToHistoryList=True,
            knowledgeBaseInfoWithFolder=KnowledgeBaseInfoWithFolder(
                knowledge_base_id=kb_id,
                folder_ids=[]
            )
        )

        url = f"{self.base_url}{self.init_session_endpoint}"
        request_json = init_request.model_dump()

        logger.info(f"åˆå§‹åŒ–ä¼šè¯URL: {url}")
        logger.info(f"åˆå§‹åŒ–ä¼šè¯å‚æ•°: {json.dumps(request_json, ensure_ascii=False, indent=2)}")

        try:
            # è·å–å®é™…è¦å‘é€çš„è¯·æ±‚å¤´
            actual_headers = dict(session.headers)
            actual_headers.update({"content-type": "application/json"})
            logger.info("å®é™…è¯·æ±‚å¤´ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰:")
            for key, value in actual_headers.items():
                if key.lower() in ['x-ima-cookie', 'authorization', 'cookie']:
                    logger.info(f"  {key}: [å·²éšè—ï¼Œé•¿åº¦={len(str(value))}]")
                else:
                    logger.info(f"  {key}: {value}")
            
            async with session.post(
                url,
                json=request_json,
                headers={"content-type": "application/json"}
            ) as response:
                logger.info(f"æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€ç : {response.status}")
                
                if response.status != 200:
                    response_text = await response.text()
                    logger.error(f"åˆå§‹åŒ–ä¼šè¯å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status}")
                    logger.error(f"å“åº”å†…å®¹: {response_text}")
                    raise ValueError(f"init_session HTTPé”™è¯¯ {response.status}: {response_text[:500]}")
                
                response.raise_for_status()

                response_data = await response.json()
                logger.info(f"åˆå§‹åŒ–ä¼šè¯å“åº”: {json.dumps(response_data, ensure_ascii=False, indent=2)}")

                # è§£æå“åº”
                init_response = InitSessionResponse(**response_data)

                if init_response.code == 0 and init_response.session_id:
                    self.current_session_id = init_response.session_id
                    self.session_initialized = True
                    logger.info(f"ä¼šè¯åˆå§‹åŒ–æˆåŠŸï¼Œsession_id: {self.current_session_id}")
                    return self.current_session_id
                else:
                    logger.error(f"ä¼šè¯åˆå§‹åŒ–å¤±è´¥ (code: {init_response.code}): {init_response.msg}")
                    raise ValueError(f"Session initialization failed (code: {init_response.code}): {init_response.msg}")

        except aiohttp.ClientError as e:
            logger.error(f"ä¼šè¯åˆå§‹åŒ–HTTPè¯·æ±‚å¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"ä¼šè¯åˆå§‹åŒ–å¼‚å¸¸: {e}")
            raise

    async def ask_question(self, question: str) -> AsyncGenerator[IMAMessage, None]:
        """å‘ IMA è¯¢é—®é—®é¢˜"""
        if not question.strip():
            raise ValueError("Question cannot be empty")

        # ç¡®ä¿tokenæœ‰æ•ˆ
        if not await self.ensure_valid_token():
            logger.error("æ— æ³•è·å–æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
            raise ValueError("Authentication failed - unable to obtain valid token")

        # æ¯æ¬¡è°ƒç”¨éƒ½åˆå§‹åŒ–æ–°ä¼šè¯ï¼Œå®ç°ä¸Šä¸‹æ–‡éš”ç¦»
        logger.info("åˆå§‹åŒ–æ–°ä¼šè¯ä»¥å®ç°ä¸Šä¸‹æ–‡éš”ç¦»...")
        try:
            await self.init_session()
            logger.info(f"ä¼šè¯åˆå§‹åŒ–æˆåŠŸï¼Œsession_id: {self.current_session_id}")
        except Exception as init_error:
            logger.error(f"ä¼šè¯åˆå§‹åŒ–å¤±è´¥: {init_error}")
            logger.error("è¿™å¯èƒ½æ˜¯å¯¼è‡´ 'No valid session ID provided' é”™è¯¯çš„åŸå› ")
            raise

        session = await self._get_session()
        request_data = self._build_request(question)

        url = f"{self.base_url}{self.api_endpoint}"
        request_json = request_data.model_dump()

        logger.debug(f"è¯·æ±‚URL: {url}")
        logger.debug(f"è¯·æ±‚å‚æ•°: {json.dumps(request_json, ensure_ascii=False, indent=2)}")

        # ç”Ÿæˆtrace_idç”¨äºè·Ÿè¸ª
        trace_id = str(uuid.uuid4())[:8]
        logger.debug(f"æœ¬æ¬¡è¯·æ±‚trace_id: {trace_id}")

        response = None
        try:
            logger.info(f"å‘é€é—®é¢˜åˆ° {url}")
            logger.info(f"ä½¿ç”¨ session_id: {request_json.get('session_id', 'N/A')}")
            
            response = await session.post(
                url,
                json=request_json,
                headers={"content-type": "application/json"}
            )

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status != 200:
                response_text = await response.text()
                logger.error(f"HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                logger.error(f"å“åº”å†…å®¹: {response_text[:500]}...")
                
                # ç‰¹åˆ«æ£€æŸ¥ 400 é”™è¯¯å’Œ session ID ç›¸å…³çš„é—®é¢˜
                if response.status == 400:
                    logger.error("=" * 60)
                    logger.error("æ”¶åˆ° HTTP 400 é”™è¯¯ - å¯èƒ½çš„åŸå› :")
                    logger.error("1. session_id æ— æ•ˆæˆ–å·²è¿‡æœŸ")
                    logger.error("2. è®¤è¯ä¿¡æ¯ï¼ˆcookies/headersï¼‰æ— æ•ˆ")
                    logger.error("3. è¯·æ±‚å‚æ•°æ ¼å¼é”™è¯¯")
                    logger.error(f"å½“å‰ä½¿ç”¨çš„ session_id: {self.current_session_id}")
                    logger.error(f"ä¼šè¯åˆå§‹åŒ–çŠ¶æ€: {self.session_initialized}")
                    logger.error("=" * 60)
                
                raise ValueError(f"HTTPè¯·æ±‚å¤±è´¥: {response.status} - {response_text[:200]}")

            # æ£€æŸ¥å“åº”ç±»å‹
            content_type = response.headers.get('content-type', '')
            logger.debug(f"å“åº”ç±»å‹: {content_type}, çŠ¶æ€ç : {response.status}")

            if 'text/event-stream' not in content_type:
                # è¯»å–å“åº”å†…å®¹è¿›è¡Œè¯Šæ–­
                response_text = await response.text()
                logger.error(f"æ„å¤–çš„å“åº”ç±»å‹: {content_type}")
                
                if not response_text.strip():
                    logger.error("æ”¶åˆ°äº†ç©ºçš„é”™è¯¯å“åº”å†…å®¹ã€‚")
                    raise ValueError(f"Expected SSE response, got {content_type} with empty body. å¯èƒ½åŸå› : 1) è®¤è¯ä¿¡æ¯é”™è¯¯ 2) è¯·æ±‚å‚æ•°é—®é¢˜ 3) APIç«¯ç‚¹å˜æ›´")

                logger.error(f"å“åº”å†…å®¹ (å‰1000å­—ç¬¦): {response_text[:1000]}")

                # å°è¯•è§£æJSONé”™è¯¯å“åº”
                try:
                    error_data = json.loads(response_text)
                    error_msg = error_data.get('msg', 'æœªçŸ¥é”™è¯¯')
                    error_code = error_data.get('code', 'N/A')
                    logger.error(f"APIé”™è¯¯å“åº” (code: {error_code}): {error_msg}")
                    logger.debug(f"å®Œæ•´é”™è¯¯è¯¦æƒ…: {json.dumps(error_data, ensure_ascii=False, indent=2)}")
                    raise ValueError(f"APIè¿”å›é”™è¯¯ (code: {error_code}): {error_msg}")
                except json.JSONDecodeError:
                    logger.error("æ— æ³•å°†é”™è¯¯å“åº”è§£æä¸ºJSONã€‚")
                    logger.error(f"åŸå§‹å“åº”å†…å®¹: {response_text}")
                    raise ValueError(f"é¢„æœŸçš„SSEå“åº”ï¼Œä½†æ”¶åˆ° {content_type}ã€‚å“åº”æ— æ³•è§£æä¸ºJSON: {response_text[:200]}")

            # å¤„ç†æµå¼å“åº”
            message_count = 0
            async for message in self._process_sse_stream(
                response,
                trace_id=trace_id,
                attempt_index=0,
                question=question
            ):
                message_count += 1
                yield message

            # ç§»é™¤è¿™ä¸ªæ—¥å¿—ï¼Œå› ä¸ºåœ¨ _process_sse_stream ä¸­å·²ç»æœ‰æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

            # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•æ¶ˆæ¯ï¼Œè‡³å°‘è¿”å›ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯
            if message_count == 0:
                logger.warning("æœªæ”¶åˆ°æœ‰æ•ˆSSEæ¶ˆæ¯")
                yield IMAMessage(
                    type=MessageType.SYSTEM,
                    content="æœªæ”¶åˆ°æœ‰æ•ˆå“åº”ï¼Œä½†è¯·æ±‚å·²æˆåŠŸå‘é€",
                    raw="No valid SSE messages received"
                )

        except asyncio.TimeoutError as e:
            logger.error(f"è¯·æ±‚è¶…æ—¶: {e}")
            raise ValueError(f"è¯·æ±‚è¶…æ—¶: {str(e)}")
        except aiohttp.ClientError as e:
            logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {e}")
            raise ValueError(f"HTTPè¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"è¯¢é—®è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä½†åŒ…è£…ä¸ºæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            raise ValueError(f"è¯¢é—®å¤±è´¥: {str(e)}")
        finally:
            # ç¡®ä¿å“åº”è¢«æ­£ç¡®å…³é—­
            if response and not response.closed:
                response.close()

    def _is_login_expired_error(self, error_str: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯ç™»å½•è¿‡æœŸç›¸å…³é”™è¯¯"""
        login_expired_patterns = [
            "Session initialization failed",
            "ç™»å½•è¿‡æœŸ",
            "ç™»å½•å¤±è´¥",
            "authentication failed",
            "è®¤è¯å¤±è´¥",
            "code: 600001",
            "code: 600002",
            "code: 600003",
            "token expired",
            "ä¼šè¯å·²è¿‡æœŸ",
            "è¯·é‡æ–°ç™»å½•",
            "unauthorized",
            "401",
            "Expected SSE response",  # æœåŠ¡å™¨è¿”å›éSSEå“åº”é€šå¸¸æ„å‘³ç€ä¼šè¯/è®¤è¯å¤±è´¥
        ]

        error_lower = error_str.lower()
        return any(pattern.lower() in error_lower for pattern in login_expired_patterns)

    async def ask_question_complete(self, question: str) -> List[IMAMessage]:
        """è·å–å®Œæ•´çš„é—®é¢˜å›ç­” - æ”¯æŒè‡ªåŠ¨ token åˆ·æ–°é‡è¯•"""
        messages = []
        max_retries = 2  # æœ€å¤§é‡è¯•æ¬¡æ•°
        
        # ç”Ÿæˆä¸»trace_idç”¨äºæ•´ä¸ªè¯·æ±‚
        main_trace_id = str(uuid.uuid4())[:8]
        logger.info(f"å¼€å§‹å®Œæ•´é—®ç­”è¯·æ±‚ (main_trace_id={main_trace_id})")

        for attempt in range(max_retries + 1):  # æ€»å…±å°è¯• max_retries + 1 æ¬¡
            logger.info(f"å°è¯• {attempt + 1}/{max_retries + 1} (main_trace_id={main_trace_id})")
            try:
                async for message in self.ask_question(question):
                    messages.append(message)

                # å¦‚æœæˆåŠŸè·å–åˆ°æ¶ˆæ¯ï¼Œç›´æ¥è¿”å›
                if messages:
                    logger.info(f"æˆåŠŸè·å– {len(messages)} æ¡æ¶ˆæ¯ (main_trace_id={main_trace_id})")
                    break

            except Exception as e:
                error_str = str(e)
                logger.error(f"Failed to get complete answer (attempt {attempt + 1}/{max_retries + 1}): {e}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç™»å½•è¿‡æœŸé”™è¯¯
                if self._is_login_expired_error(error_str):
                    if attempt < max_retries:
                        logger.info(f"æ£€æµ‹åˆ°ç™»å½•/è®¤è¯è¿‡æœŸé”™è¯¯ï¼Œå°è¯•åˆ·æ–° token... (é”™è¯¯: {error_str[:100]})")

                        # å°è¯•åˆ·æ–° token
                        refresh_success = await self.refresh_token()
                        if refresh_success:
                            logger.info("Token åˆ·æ–°æˆåŠŸï¼Œé‡æ–°å°è¯•ä¼šè¯åˆå§‹åŒ–...")
                            # é‡ç½®ä¼šè¯çŠ¶æ€ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
                            self.session_initialized = False
                            self.current_session_id = None
                            # å…³é—­ç°æœ‰ä¼šè¯ï¼Œé‡æ–°åˆ›å»º
                            if self.session and not self.session.closed:
                                await self.session.close()
                                self.session = None
                            # é‡ç½®æ¶ˆæ¯åˆ—è¡¨ï¼Œå‡†å¤‡é‡æ–°å°è¯•
                            messages = []
                            continue
                        else:
                            logger.warning("Token åˆ·æ–°å¤±è´¥ï¼Œæ— æ³•æ¢å¤ä¼šè¯")
                    else:
                        logger.error(f"å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œtoken åˆ·æ–°å¤±è´¥ã€‚åŸå§‹é”™è¯¯: {error_str}")
                else:
                    # å¦‚æœä¸æ˜¯ç™»å½•è¿‡æœŸé”™è¯¯ï¼Œç›´æ¥è®°å½•é”™è¯¯å¹¶é‡è¯•
                    if attempt < max_retries:
                        logger.info(f"éç™»å½•è¿‡æœŸé”™è¯¯ï¼Œé‡è¯•ä¸­... (é”™è¯¯: {error_str[:100]})")
                        # é‡ç½®æ¶ˆæ¯åˆ—è¡¨ï¼Œå‡†å¤‡é‡æ–°å°è¯•
                        messages = []
                        # çŸ­æš‚å»¶è¿Ÿåé‡è¯•
                        await asyncio.sleep(1)
                        continue

                # å¦‚æœå·²ç»é‡è¯•å®Œæˆï¼Œè®°å½•æœ€ç»ˆé”™è¯¯
                if attempt == max_retries:
                    error_message = IMAMessage(
                        type=MessageType.SYSTEM,
                        content=f"è·å–å›ç­”å¤±è´¥: {error_str}",
                        raw=str(e)
                    )
                    messages.append(error_message)

        return messages

    def _extract_text_content(self, messages: List[IMAMessage]) -> str:
        """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–æ–‡æœ¬å†…å®¹ - ç°åœ¨åªå¤„ç†answerå’Œcontext_refsçš„æ‹¼æ¥"""
        if not messages:
            return "æ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”"

        content_parts = []

        for message in messages:
            if isinstance(message, TextMessage) and message.text:
                content_parts.append(message.text)
            elif hasattr(message, 'content') and message.content:
                content_parts.append(message.content)

        # æ‹¼æ¥æ‰€æœ‰å†…å®¹
        final_result = ''.join(content_parts).strip()

        # æ¸…ç†å’Œæ ¼å¼åŒ–ç»“æœ
        final_result = self._clean_response_content(final_result)

        logger.debug(f"æœ€ç»ˆå“åº”å†…å®¹é•¿åº¦: {len(final_result)}")
        return final_result

    def _clean_response_content(self, content: str) -> str:
        """æ¸…ç†å’Œæ ¼å¼åŒ–å“åº”å†…å®¹"""
        if not content:
            return content

        # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
        lines = content.split('\n')
        cleaned_lines = []
        prev_empty = False

        for line in lines:
            line = line.strip()
            if line:
                cleaned_lines.append(line)
                prev_empty = False
            elif not prev_empty:
                cleaned_lines.append('')
                prev_empty = True

        return '\n'.join(cleaned_lines)

    
    def _extract_knowledge_info(self, messages: List[IMAMessage]) -> List[Dict[str, Any]]:
        """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–çŸ¥è¯†åº“ä¿¡æ¯"""
        knowledge_items = []

        for message in messages:
            if isinstance(message, KnowledgeBaseMessage) and message.medias:
                for media in message.medias:
                    knowledge_items.append({
                        'id': media.id,
                        'title': media.title,
                        'subtitle': media.subtitle,
                        'introduction': media.introduction,
                        'timestamp': media.timestamp,
                        'knowledge_base': media.knowledge_base_info.name if media.knowledge_base_info else None
                    })

        return knowledge_items

    async def validate_config(self) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        try:
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•é—®é¢˜
            test_messages = await self.ask_question_complete("æµ‹è¯•è¿æ¥")
            return len(test_messages) > 0
        except Exception as e:
            logger.error(f"Config validation failed: {e}")
            return False

    async def get_status(self) -> IMAStatus:
        """è·å–å®¢æˆ·ç«¯çŠ¶æ€"""
        status = IMAStatus()

        if not self.config:
            return status

        status.is_configured = True

        try:
            # éªŒè¯è®¤è¯çŠ¶æ€
            is_valid = await self.validate_config()
            status.is_authenticated = is_valid
            status.last_test_time = datetime.now()

            if not is_valid:
                status.error_message = "è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"

        except Exception as e:
            status.error_message = str(e)
            logger.error(f"Failed to get status: {e}")

        return status


class IMAToolExecutor:
    """IMA å·¥å…·æ‰§è¡Œå™¨"""

    def __init__(self, client: IMAAPIClient):
        self.client = client

    async def ask_question(self, question: str, include_knowledge: bool = True) -> MCPToolResult:
        """æ‰§è¡Œè¯¢é—®é—®é¢˜å·¥å…·"""
        try:
            messages = await self.client.ask_question_complete(question)

            if not messages:
                return MCPToolResult(
                    success=False,
                    content="",
                    error="æœªæ”¶åˆ°å“åº”"
                )

            # æå–ä¸»è¦å›ç­”å†…å®¹
            answer_text = self.client._extract_text_content(messages)

            # æ„å»ºå“åº”å†…å®¹
            content_parts = [f"**é—®é¢˜**: {question}\n\n**å›ç­”**:\n{answer_text}"]

            # æ·»åŠ çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_knowledge:
                knowledge_info = self.client._extract_knowledge_info(messages)
                if knowledge_info:
                    content_parts.append("\n\n**å‚è€ƒèµ„æ–™**:")
                    for i, item in enumerate(knowledge_info[:5], 1):  # æœ€å¤šæ˜¾ç¤º5ä¸ªå‚è€ƒèµ„æ–™
                        content_parts.append(f"{i}. {item['title']}")
                        if item.get('introduction'):
                            content_parts.append(f"   {item['introduction'][:100]}...")

            final_content = '\n'.join(content_parts)

            return MCPToolResult(
                success=True,
                content=final_content,
                metadata={
                    'message_count': len(messages),
                    'knowledge_sources': len(self.client._extract_knowledge_info(messages))
                }
            )

        except Exception as e:
            logger.error(f"Failed to execute ask_question: {e}")
            return MCPToolResult(
                success=False,
                content="",
                error=f"è¯¢é—®å¤±è´¥: {str(e)}"
            )

  
